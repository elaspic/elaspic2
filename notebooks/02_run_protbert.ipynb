{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Calculate features using [ProtBert](https://github.com/agemagician/ProtTrans).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import os\n",
    "import re\n",
    "import socket\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import kmbio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from ev2.plugins.protbert import (\n",
    "    ProtBert,\n",
    "    ProtBertAnalyzeError,\n",
    "    ProtBertBuildError,\n",
    ")\n",
    "from kmbio import PDB\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProtBert.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = Path(\"02_run_protbert\").resolve()\n",
    "NOTEBOOK_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "NOTEBOOK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DATAPKG_OUTPUT_DIR\" in os.environ:\n",
    "    OUTPUT_DIR = Path(os.getenv(\"DATAPKG_OUTPUT_DIR\")).joinpath(\"elaspic-v2\").resolve()\n",
    "else:\n",
    "    OUTPUT_DIR = NOTEBOOK_DIR.parent\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (slurm_tmpdir := os.getenv(\"SLURM_TMPDIR\")) is not None:\n",
    "    os.environ[\"TMPDIR\"] = slurm_tmpdir\n",
    "    \n",
    "print(tempfile.gettempdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"scinet\" in socket.gethostname():\n",
    "    CPU_COUNT = 40\n",
    "else:\n",
    "    CPU_COUNT = max(1, len(os.sched_getaffinity(0)))\n",
    "\n",
    "CPU_COUNT = CPU_COUNT // 8\n",
    "\n",
    "CPU_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = os.getenv(\"DATASET_NAME\")\n",
    "TASK_ID = os.getenv(\"SLURM_ARRAY_TASK_ID\")\n",
    "TASK_COUNT = os.getenv(\"ORIGINAL_ARRAY_TASK_COUNT\") or os.getenv(\"SLURM_ARRAY_TASK_COUNT\")\n",
    "\n",
    "TASK_ID = int(TASK_ID) if TASK_ID is not None else None\n",
    "TASK_COUNT = int(TASK_COUNT) if TASK_COUNT is not None else None\n",
    "\n",
    "DATASET_NAME, TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = TASK_ID is None\n",
    "\n",
    "if DEBUG:\n",
    "    DATASET_NAME = \"elaspic-training-set-core\"\n",
    "    TASK_ID = 103\n",
    "    TASK_COUNT = 162\n",
    "else:\n",
    "    assert DATASET_NAME is not None\n",
    "    assert TASK_ID is not None\n",
    "    assert TASK_COUNT is not None\n",
    "\n",
    "DATASET_NAME, TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = OUTPUT_DIR.joinpath(\"01_load_data\", f\"{DATASET_NAME}.parquet\")\n",
    "\n",
    "input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = pq.ParquetFile(input_file)\n",
    "\n",
    "pfile.num_row_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TASK_COUNT == pfile.num_row_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DF = pfile.read_row_group(TASK_ID - 1).to_pandas(integer_object_nulls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(INPUT_DF.head(2))\n",
    "print(len(INPUT_DF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = OUTPUT_DIR.joinpath(NOTEBOOK_DIR.name)\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_mutation(mutation):\n",
    "    return f\"{mutation[-1]}{mutation[1:-1]}{mutation[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "for row in tqdm(INPUT_DF.itertuples(), total=len(INPUT_DF)):\n",
    "\n",
    "    data_core = ProtBert.build(row.protein_sequence, None)\n",
    "    if row.ligand_sequence is not None:\n",
    "        data_interface = ProtBert.build(row.protein_sequence, row.ligand_sequence)\n",
    "    else:\n",
    "        data_interface = None\n",
    "\n",
    "    _seen = set()\n",
    "    for idx in range(len(row.mutation)):\n",
    "        mutation = row.mutation[idx]\n",
    "        if mutation in _seen:\n",
    "            print(\n",
    "                f\"Already added mutation '{mutation}' for protein ({row.unique_id}, {row.dataset}, {row.name}).\"\n",
    "            )\n",
    "            continue\n",
    "        _seen.add(mutation)\n",
    "\n",
    "        aa = \"GVALICMFWPDESTYQNKRH\"\n",
    "        if re.search(f\"^[{aa}][1-9]+[0-9]*[{aa}]$\", mutation) is None:\n",
    "            print(f\"Skipping mutation {mutation} because it appears to be malformed.\")\n",
    "            continue\n",
    "\n",
    "        if mutation[0] == mutation[-1]:\n",
    "            print(f\"Skipping mutation {mutation} because the wildtype and mutant residues are the same.\")\n",
    "            continue\n",
    "\n",
    "        data_mut = {\n",
    "            \"unique_id\": row.unique_id,\n",
    "            \"mutation\": row.mutation[idx],\n",
    "            \"effect\": row.effect[idx],\n",
    "            \"rev\": False,\n",
    "        }\n",
    "        tasks.append((data_core, data_interface, data_mut))\n",
    "\n",
    "        data_mut = {\n",
    "            \"unique_id\": row.unique_id,\n",
    "            \"mutation\": reverse_mutation(row.mutation[idx]),\n",
    "            \"effect\": -row.effect[idx],\n",
    "            \"rev\": True,\n",
    "        }\n",
    "        tasks.append((data_core, data_interface, data_mut))\n",
    "\n",
    "len(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(input):\n",
    "    data_core, data_interface, data_mut = input\n",
    "    mutation = data_mut[\"mutation\"]\n",
    "    try:\n",
    "        results_core = ProtBert.analyze_mutation(f\"A_{mutation}\", data_core)\n",
    "        if data_interface is not None:\n",
    "            results_interface = ProtBert.analyze_mutation(f\"A_{mutation}\", data_interface)\n",
    "        else:\n",
    "            results_interface = {}\n",
    "    except ProtBertAnalyzeError as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    results = {\n",
    "        **data_mut,\n",
    "        **{f\"protbert_core_{key}\": value for key, value in results_core.items()},\n",
    "        **{f\"protbert_interface_{key}\": value for key, value in results_interface.items()},\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = worker(tasks[647])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# _ = plt.hist(\n",
    "#     np.array(result[\"protbert_core_features_residue_wt\"])\n",
    "#     - np.array(result[\"protbert_core_features_residue_mut\"]),\n",
    "#     label=\"Residue wt → mut\",\n",
    "#     alpha=0.5,\n",
    "#     bins=100,\n",
    "#     range=(-0.1, 0.2),\n",
    "# )\n",
    "# _ = plt.hist(\n",
    "#     np.array(result[\"protbert_core_features_residue_wt\"])\n",
    "#     - np.array(result[\"protbert_interface_features_residue_wt\"]),\n",
    "#     label=\"Residue core → interface\",\n",
    "#     alpha=0.5,\n",
    "#     bins=100,\n",
    "#     range=(-0.1, 0.2),\n",
    "# )\n",
    "# _ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# _ = plt.hist(\n",
    "#     np.array(result[\"protbert_core_features_protein_wt\"])\n",
    "#     - np.array(result[\"protbert_core_features_protein_mut\"]),\n",
    "#     label=\"Protein wt → mut\",\n",
    "#     alpha=0.5,\n",
    "#     bins=100,\n",
    "#     range=(-0.1, 0.2),\n",
    "# )\n",
    "# _ = plt.hist(\n",
    "#     np.array(result[\"protbert_core_features_protein_wt\"])\n",
    "#     - np.array(result[\"protbert_interface_features_protein_wt\"]),\n",
    "#     label=\"Protein core → interface\",\n",
    "#     alpha=0.5,\n",
    "#     bins=100,\n",
    "#     range=(-0.1, 0.2),\n",
    "# )\n",
    "# _ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with concurrent.futures.ProcessPoolExecutor(CPU_COUNT) as pool:\n",
    "#     results = list(tqdm(pool.map(worker, tasks), total=len(tasks)))\n",
    "\n",
    "# results_df = pd.DataFrame([l for l in results if l is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(tqdm((worker(task) for task in tasks), total=len(tasks)))\n",
    "\n",
    "results_df = pd.DataFrame([l for l in results if l is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = output_dir.joinpath(f\"{DATASET_NAME}-{TASK_ID}-{TASK_COUNT}.parquet\")\n",
    "\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(pa.Table.from_pandas(results_df, preserve_index=False), output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
