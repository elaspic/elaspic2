{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "```bash\n",
    "sbatch --array=1-46%1 --time=3:00:00 --export=NOTEBOOK_PATH=\"$(realpath 05_feature_elimination.ipynb)\",COI=core ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "sbatch --array=1-136%1 --time=3:00:00 --export=NOTEBOOK_PATH=\"$(realpath 05_feature_elimination.ipynb)\",COI=interface ../scripts/run_notebook_cpu.sh\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shlex\n",
    "import subprocess\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "import concurrent.futures\n",
    "import itertools\n",
    "import lightgbm\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import socket\n",
    "\n",
    "import math\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = Path(\"05_feature_elimination\").resolve()\n",
    "NOTEBOOK_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "NOTEBOOK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COI = os.getenv(\"COI\")\n",
    "TASK_ID = os.getenv(\"SLURM_ARRAY_TASK_ID\")\n",
    "TASK_COUNT = os.getenv(\"ORIGINAL_ARRAY_TASK_COUNT\") or os.getenv(\"SLURM_ARRAY_TASK_COUNT\")\n",
    "\n",
    "TASK_ID = int(TASK_ID) if TASK_ID is not None else None\n",
    "TASK_COUNT = int(TASK_COUNT) if TASK_COUNT is not None else None\n",
    "\n",
    "TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = TASK_ID is None\n",
    "\n",
    "if DEBUG:\n",
    "    COI = \"interface\"\n",
    "    TASK_ID = 1\n",
    "    TASK_COUNT = 136\n",
    "else:\n",
    "    assert COI in [\"core\", \"interface\"]\n",
    "    assert TASK_ID is not None\n",
    "    assert TASK_COUNT is not None\n",
    "\n",
    "COI, TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DATAPKG_OUTPUT_DIR\" in os.environ:\n",
    "    OUTPUT_DIR = Path(os.getenv(\"DATAPKG_OUTPUT_DIR\")).joinpath(\"elaspic-v2\").resolve()\n",
    "else:\n",
    "    OUTPUT_DIR = NOTEBOOK_DIR.parent\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"scinet\" in socket.gethostname():\n",
    "    CPU_COUNT = 40\n",
    "else:\n",
    "    CPU_COUNT = max(1, len(os.sched_getaffinity(0)))\n",
    "\n",
    "CPU_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (slurm_tmpdir := os.getenv(\"SLURM_TMPDIR\")) is not None:\n",
    "    os.environ[\"TMPDIR\"] = slurm_tmpdir\n",
    "\n",
    "print(tempfile.gettempdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with NOTEBOOK_DIR.parent.joinpath(\"04_train_model\", f\"pca-columns-{COI}.parquet\").open(\"rt\") as fin:\n",
    "    pca_columns = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_df = pq.read_table(NOTEBOOK_DIR.parent.joinpath(\"04_train_model\", f\"sequences-{COI}.parquet\")).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_df = pq.read_table(NOTEBOOK_DIR.parent.joinpath(\"04_train_model\", f\"input-train-{COI}.parquet\")).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_df = pq.read_table(NOTEBOOK_DIR.parent.joinpath(\"04_train_model\", f\"input-test-{COI}.parquet\")).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_splits = []\n",
    "for idx in range(6):\n",
    "    train_df = pq.read_table(NOTEBOOK_DIR.parent.joinpath(\"04_train_model\", f\"xval-train-{COI}-{idx}.parquet\")).to_pandas()\n",
    "    test_df = pq.read_table(NOTEBOOK_DIR.parent.joinpath(\"04_train_model\", f\"xval-test-{COI}-{idx}.parquet\")).to_pandas()\n",
    "    train_test_splits.append((train_df, test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_columns = [\n",
    "#     c\n",
    "#     for c in list(train_test_splits[0][0])\n",
    "#     if (c.endswith(\"_wt\") or c.endswith(\"_mut\") or c.endswith(\"_change\") or c.endswith(\"_pc\"))\n",
    "#     and not (c.endswith(\"dg_change\") or c.startswith(\"rosetta_\"))\n",
    "# ]\n",
    "\n",
    "with open(NOTEBOOK_DIR.joinpath(f\"feature-columns-{COI}-{TASK_ID - 1}.json\"), \"rt\") as fin:\n",
    "    feature_columns = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(df):\n",
    "    effect = df[\"effect\"].values.copy()\n",
    "\n",
    "    mask = df[\"effect_type\"].str.startswith(\"ΔΔG\")\n",
    "    effect[mask] *= 0.8\n",
    "\n",
    "    mask = df[\"effect_type\"] == \"Deleteriousness class\"\n",
    "    effect[mask] *= 1\n",
    "\n",
    "    mask = df[\"effect_type\"] == \"Stability score change\"\n",
    "    effect[mask] *= 5\n",
    "\n",
    "    mask = df[\"effect_type\"] == \"Deleteriousness score\"\n",
    "    if mask.any():\n",
    "        assert effect[mask].min() >= -5 and effect[mask].max() <= 5\n",
    "\n",
    "    mask = df[\"effect_type\"] == \"Deep mutation scan\"\n",
    "    effect[mask] *= 4\n",
    "\n",
    "    effect = np.rint(np.clip(effect, -5, 5) * 100 + 500)\n",
    "    return effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_df[\"effect_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group(df, max_group_size=100):\n",
    "    assert df[\"unique_id\"].is_monotonic_increasing\n",
    "    vc = df[\"unique_id\"].value_counts()\n",
    "    groups = [vc[uid] for uid in df[\"unique_id\"].unique()]\n",
    "    if max_group_size:\n",
    "        old_groups, groups = groups, []\n",
    "        for idx, group in enumerate(old_groups):\n",
    "            if group <= max_group_size:\n",
    "                groups.append(group)\n",
    "            else:\n",
    "                num_subgroups = math.ceil(group / max_group_size)\n",
    "                num_per_group = math.floor(group / num_subgroups)\n",
    "                subgroups = [num_per_group] * num_subgroups\n",
    "                if (remainder := group - sum(subgroups)):\n",
    "                    assert remainder < num_subgroups\n",
    "                    for remainder_idx in range(remainder):\n",
    "                        subgroups[remainder_idx] += 1\n",
    "                groups.extend(subgroups)\n",
    "    assert sum(groups) == len(df), (sum(groups), len(df))\n",
    "    assert not max_group_size or max(groups) <= max_group_size\n",
    "    return np.array(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COI == \"core\":\n",
    "    max_group_size = 100\n",
    "else:\n",
    "    max_group_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(input, feature_columns, param):\n",
    "    train_df, test_df = input\n",
    "\n",
    "    train_ds = lgb.Dataset(\n",
    "        train_df[feature_columns],\n",
    "        label=get_label(train_df),\n",
    "        group=get_group(train_df, max_group_size=max_group_size),\n",
    "    )\n",
    "\n",
    "    valid_ds = lgb.Dataset(\n",
    "        test_df[feature_columns],\n",
    "        label=get_label(test_df),\n",
    "        group=get_group(test_df, max_group_size=max_group_size),\n",
    "        reference=train_ds,\n",
    "    )\n",
    "\n",
    "    bst = lgb.train(\n",
    "        param,\n",
    "        train_ds,\n",
    "        valid_sets=[valid_ds],\n",
    "        num_boost_round=100,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skempi_unique_ids = set(input_train_df[input_train_df[\"dataset\"] == \"skempi++\"][\"unique_id\"].unique())\n",
    "skempi_sequences = set(tuple(s) for s in sequence_df[sequence_df[\"unique_id\"].isin(skempi_unique_ids)][[\"protein_sequence\", \"ligand_sequence\"]].values)\n",
    "\n",
    "skempi_v2_unique_ids = set(input_train_df[input_train_df[\"dataset\"] == \"skempi-v2\"][\"unique_id\"].unique())\n",
    "skempi_v2_unique_ids = {\n",
    "    uid for uid, pseq, lseq\n",
    "    in sequence_df[sequence_df[\"unique_id\"].isin(skempi_v2_unique_ids)][[\"unique_id\", \"protein_sequence\", \"ligand_sequence\"]].values\n",
    "    if (pseq, lseq) not in skempi_sequences\n",
    "}\n",
    "\n",
    "\n",
    "def get_aggregate_spearmanr(result_df, datasets):\n",
    "    corrs = []\n",
    "    for dataset, effect_type, *_ in datasets:\n",
    "        df = result_df[\n",
    "            (result_df[\"dataset\"] == dataset)\n",
    "            & (result_df[\"effect_type\"] == effect_type)\n",
    "            & (result_df[\"rev\"] == False)\n",
    "        ]\n",
    "\n",
    "        if dataset == \"skempi-v2\":\n",
    "            df = df[df[\"unique_id\"].isin(skempi_v2_unique_ids)]\n",
    "\n",
    "        df = df.dropna(subset=[\"effect\", \"ddg_pred\"])\n",
    "        \n",
    "        corr = stats.spearmanr(df[\"effect\"], df[\"ddg_pred\"])[0]\n",
    "        corrs.append(corr)\n",
    "    return sum(corrs) / len(corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COI == \"core\":\n",
    "    columns_full = [\n",
    "        \"ddg_pred\",\n",
    "        \"elaspic_score\",\n",
    "        \"foldx_score\",\n",
    "        \"rosetta_dg_change\",\n",
    "    ]\n",
    "\n",
    "    datasets_eval = [\n",
    "        [\"protherm++\", \"ΔΔG\", columns_full],\n",
    "        [\"humsavar\", \"Deleteriousness class\", columns_full],\n",
    "        [\"clinvar\", \"Deleteriousness class\", columns_full],\n",
    "        [\"cosmic\", \"Deleteriousness class\", columns_full],\n",
    "        [\"taipale\", \"ΔΔG\", columns_full],\n",
    "        # [\"taipale_gpca\", \"ΔΔG\", columns_full],\n",
    "        # [\"cagi5_frataxin\", \"ΔΔG\", [\"ddg_pred\"]],\n",
    "        [\"rocklin-2017-core\", \"Stability score change\", [\"ddg_pred\", \"rosetta_dg_change\"]],\n",
    "        [\"dunham_2020_tianyu\", \"Deep mutation scan\", [\"ddg_pred\", \"rosetta_dg_change\"]],\n",
    "        # [\"protherm-dagger-core\", \"ΔΔG\", [\"ddg_pred\", \"rosetta_dg_change\"]],\n",
    "    ]\n",
    "else:\n",
    "    columns_full = [\n",
    "        \"ddg_pred\",\n",
    "        \"elaspic_score\",\n",
    "        \"foldx_score\",\n",
    "        \"rosetta_complex_dg_change\",\n",
    "    ]\n",
    "\n",
    "    datasets_eval = [\n",
    "        [\"skempi++\", \"ΔΔG\", columns_full],\n",
    "        [\"humsavar\", \"Deleteriousness class\", columns_full],\n",
    "        [\"clinvar\", \"Deleteriousness class\", columns_full],\n",
    "        [\"cosmic\", \"Deleteriousness class\", columns_full],\n",
    "        [\"ab_bind\", \"ΔΔG\", [\"ddg_pred\", \"elaspic_score\", \"foldx_score\"]],\n",
    "        # [\"taipale\", \"ΔΔG\", eval_columns],\n",
    "        [\"skempi-v2\", \"ΔΔG (from affinity)\", [\"ddg_pred\", \"rosetta_complex_dg_change\"]],\n",
    "        # [\"skempi-v2\", \"ΔΔG (from Kon/Koff)\", [\"ddg_pred\", \"rosetta_complex_dg_change\"]],\n",
    "        [\"dunham_2020_tianyu\", \"Deep mutation scan\", [\"ddg_pred\", \"rosetta_complex_dg_change\"]],\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_param = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"verbosity\": -1,\n",
    "    \"eval_at\": 1_000_000,\n",
    "    \"label_gain\": [np.log2(2 + i) for i in range(0, 1_001)],\n",
    "    \"force_col_wise\": True,\n",
    "    \"num_threads\": 40,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        **const_param,\n",
    "        # num_trees = 100\n",
    "#         \"learning_rate\": trial.suggest_loguniform(\"lambda_l1\", 1e-3, 1.0),\n",
    "#         \"num_iterations\": trial.suggest_int(\"num_leaves\", 64, 256),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 512),  # 256\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 5, 200), # 100\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "    }\n",
    "\n",
    "    result_dfs = []\n",
    "    for train_df, test_df in train_test_splits:\n",
    "        assert not set(train_df[\"cluster_id\"]) & set(test_df[\"cluster_id\"])\n",
    "        bst = train_model((train_df, test_df), feature_columns, param)\n",
    "        \n",
    "        test_df = test_df.copy()\n",
    "        test_df[\"ddg_pred\"] = bst.predict(\n",
    "            test_df[feature_columns], num_iteration=bst.best_iteration\n",
    "        )\n",
    "        result_dfs.append(test_df)\n",
    "    result_df = pd.concat(result_dfs, ignore_index=True)\n",
    "    \n",
    "    score = get_aggregate_spearmanr(result_df, datasets_eval)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100, n_jobs=2)\n",
    "print(f\"Elaspsed: {time.perf_counter() - start_time}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = {\n",
    "    \"best_score\": study.best_value,\n",
    "    \"const_params\": const_param,\n",
    "    \"best_params\": study.best_params,\n",
    "    \"feature_columns\": feature_columns,\n",
    "    \"feature_elimination_stats\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    **const_param,\n",
    "    **study.best_params,\n",
    "    \"num_threads\": 80,\n",
    "}\n",
    "\n",
    "\n",
    "for i, feature_to_eliminate in enumerate(feature_columns):\n",
    "    print(i, feature_to_eliminate, end=\" \")\n",
    "    \n",
    "    feature_columns_elim = [c for c in feature_columns if c != feature_to_eliminate]\n",
    "    assert len(feature_columns_elim) == len(feature_columns) - 1\n",
    "\n",
    "    result_dfs = []\n",
    "    for train_df, test_df in train_test_splits:\n",
    "        assert not set(train_df[\"cluster_id\"]) & set(test_df[\"cluster_id\"])\n",
    "        bst = train_model((train_df, test_df), feature_columns_elim, param)\n",
    "        \n",
    "        test_df = test_df.copy()\n",
    "        test_df[\"ddg_pred\"] = bst.predict(\n",
    "            test_df[feature_columns_elim], num_iteration=bst.best_iteration\n",
    "        )\n",
    "        result_dfs.append(test_df)\n",
    "    result_df = pd.concat(result_dfs, ignore_index=True)\n",
    "    \n",
    "    score = get_aggregate_spearmanr(result_df, datasets_eval)\n",
    "    print(score)\n",
    "\n",
    "    RESULTS[\"feature_elimination_stats\"].append([feature_to_eliminate, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_elimination_stats = (\n",
    "    pd.DataFrame(RESULTS[\"feature_elimination_stats\"], columns=[\"feature_name\", \"score\"])\n",
    "    .sort_values(\"score\", ascending=False)\n",
    ")\n",
    "\n",
    "feature_elimination_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_row = feature_elimination_stats.iloc[0]\n",
    "\n",
    "final_feature_to_eliminate = top_row[\"feature_name\"]\n",
    "print(final_feature_to_eliminate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_new = [c for c in feature_columns if c != final_feature_to_eliminate]\n",
    "assert len(feature_columns_new) == len(feature_columns) - 1\n",
    "\n",
    "feature_columns_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(NOTEBOOK_DIR.joinpath(f\"feature-columns-{COI}-{TASK_ID}.json\"), \"wt\") as fout:\n",
    "    json.dump(feature_columns_new, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(NOTEBOOK_DIR.joinpath(f\"stats-{COI}-{TASK_ID}.json\"), \"wt\") as fout:\n",
    "    json.dump(RESULTS, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
