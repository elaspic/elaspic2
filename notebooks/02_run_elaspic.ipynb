{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import socket\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import kmbio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from elaspic2.plugins.proteinsolver import (\n",
    "    ProteinSolver,\n",
    "    ProteinSolverAnalyzeError,\n",
    "    ProteinSolverBuildError,\n",
    ")\n",
    "from kmbio import PDB\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProteinSolver.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = Path(\"02_run_elaspic\").resolve()\n",
    "NOTEBOOK_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "NOTEBOOK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DATAPKG_OUTPUT_DIR\" in os.environ:\n",
    "    OUTPUT_DIR = Path(os.getenv(\"DATAPKG_OUTPUT_DIR\")).joinpath(\"elaspic2\").resolve()\n",
    "else:\n",
    "    OUTPUT_DIR = NOTEBOOK_DIR.parent\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (slurm_tmpdir := os.getenv(\"SLURM_TMPDIR\")) is not None:\n",
    "    os.environ[\"TMPDIR\"] = slurm_tmpdir\n",
    "    \n",
    "print(tempfile.gettempdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"scinet\" in socket.gethostname():\n",
    "    CPU_COUNT = 40\n",
    "else:\n",
    "    CPU_COUNT = max(1, len(os.sched_getaffinity(0)))\n",
    "\n",
    "CPU_COUNT = CPU_COUNT // 2\n",
    "\n",
    "CPU_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = os.getenv(\"DATASET_NAME\")\n",
    "TASK_ID = os.getenv(\"SLURM_ARRAY_TASK_ID\")\n",
    "TASK_COUNT = os.getenv(\"ORIGINAL_ARRAY_TASK_COUNT\") or os.getenv(\"SLURM_ARRAY_TASK_COUNT\")\n",
    "\n",
    "TASK_ID = int(TASK_ID) if TASK_ID is not None else None\n",
    "TASK_COUNT = int(TASK_COUNT) if TASK_COUNT is not None else None\n",
    "\n",
    "DATASET_NAME, TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = TASK_ID is None\n",
    "\n",
    "if DEBUG:\n",
    "    DATASET_NAME = \"starr-2020-interface\"\n",
    "    TASK_ID = 1\n",
    "    TASK_COUNT = 1\n",
    "else:\n",
    "    assert DATASET_NAME is not None\n",
    "    assert TASK_ID is not None\n",
    "    assert TASK_COUNT is not None\n",
    "\n",
    "DATASET_NAME, TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = OUTPUT_DIR.joinpath(\"01_load_data\", f\"{DATASET_NAME}.parquet\")\n",
    "\n",
    "input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = pq.ParquetFile(input_file)\n",
    "\n",
    "pfile.num_row_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TASK_COUNT == pfile.num_row_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DF = pfile.read_row_group(TASK_ID - 1).to_pandas(integer_object_nulls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(INPUT_DF.head(2))\n",
    "print(len(INPUT_DF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = OUTPUT_DIR.joinpath(NOTEBOOK_DIR.name)\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "for row in INPUT_DF.itertuples():\n",
    "    for mutation, effect in zip(row.mutation, row.effect):\n",
    "        if pd.isnull(effect):\n",
    "            print(f\"Skipping mutation {mutation} because the effect is unknown ({effect}).\")\n",
    "            continue\n",
    "        input_data.append({\n",
    "            \"unique_id\": row.unique_id,\n",
    "            \"mutation\": mutation,\n",
    "            \"effect\": effect,\n",
    "            \"effect_type\": row.effect_type,\n",
    "        })\n",
    "\n",
    "input_df = pd.DataFrame(input_data)\n",
    "len(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET_NAME == \"starr-2020-core\":\n",
    "    elaspic_path = Path(\"/home/kimlab1/database_data/elaspic_v2/user_input/spike-sars2-co/.elaspic\").resolve(strict=True)\n",
    "elif DATASET_NAME == \"starr-2020-interface\":\n",
    "    elaspic_path = Path(\"/home/kimlab1/database_data/elaspic_v2/user_input/spike-sars2-in/.elaspic\").resolve(strict=True)\n",
    "else:\n",
    "    raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_core = []\n",
    "results_interface = []\n",
    "\n",
    "for file in os.listdir(elaspic_path):\n",
    "    if file.startswith(\"mutation_\"):\n",
    "        mutation = file.split(\".\")[0].split(\"_\")[2]\n",
    "#         print(mutation, file)\n",
    "        with elaspic_path.joinpath(file).open(\"rt\") as fin:\n",
    "            data_list = json.load(fin)\n",
    "        for data in data_list:\n",
    "            assert mutation == data[\"mutation\"]\n",
    "            if \"idxs\" in data:\n",
    "                if DATASET_NAME.endswith(\"-core\"):\n",
    "                    continue\n",
    "                if data[\"idxs\"] != [0, 1]:\n",
    "                    print(f\"Skipping interaction {data}.\")\n",
    "                    continue\n",
    "                foldx_score_wt = float(data[\"analyse_complex_energy_wt\"].split(\",\")[0])\n",
    "                foldx_score_mut = float(data[\"analyse_complex_energy_mut\"].split(\",\")[0])\n",
    "                results_interface.append({\n",
    "                    \"mutation\": mutation,\n",
    "                    \"elaspic_score\": float(data[\"ddg\"]),\n",
    "                    \"provean_score\": float(data[\"provean_score\"]),\n",
    "                    \"foldx_score\": foldx_score_mut - foldx_score_wt,\n",
    "                })\n",
    "            else:\n",
    "                foldx_score_wt = float(data[\"stability_energy_wt\"].split(\",\")[0])\n",
    "                foldx_score_mut = float(data[\"stability_energy_mut\"].split(\",\")[0])\n",
    "                results_core.append({\n",
    "                    \"mutation\": mutation,\n",
    "                    \"elaspic_score\": float(data[\"ddg\"]),\n",
    "                    \"provean_score\": float(data[\"provean_score\"]),\n",
    "                    \"foldx_score\": foldx_score_mut - foldx_score_wt,\n",
    "\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_core_df = pd.DataFrame(results_core)\n",
    "\n",
    "len(results_core_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_interface_df = pd.DataFrame(results_interface, columns=results_core_df.columns)\n",
    "results_interface_df[\"provean_score\"] = results_interface_df[\"provean_score\"].fillna(np.nan)\n",
    "\n",
    "len(results_interface_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_core_df.merge(results_interface_df, on=[\"mutation\"], how=\"left\", suffixes=(\"_core\", \"_interface\"))\n",
    "\n",
    "results_df[\"elaspic_score\"] = [\n",
    "    ((elaspic_score_interface) if pd.notnull(elaspic_score_interface) else elaspic_score_core)\n",
    "    for elaspic_score_core, elaspic_score_interface\n",
    "    in results_df[[\"elaspic_score_core\", \"elaspic_score_interface\"]].values\n",
    "]\n",
    "\n",
    "# if results_df[\"provean_score_interface\"].notnull().any():\n",
    "#     assert np.allclose(results_df[\"provean_score_core\"].values, results_df[\"provean_score_interface\"].values, equal_nan=True)\n",
    "results_df[\"provean_score\"] = results_df[[\"provean_score_core\"]].mean(axis=1)\n",
    "\n",
    "results_df[\"foldx_score\"] = [\n",
    "    ((foldx_score_interface) if pd.notnull(foldx_score_interface) else foldx_score_core)\n",
    "    for foldx_score_core, foldx_score_interface\n",
    "    in results_df[[\"foldx_score_core\", \"foldx_score_interface\"]].values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wresults_df = input_df.merge(results_df, on=[\"mutation\"])\n",
    "len(input_wresults_df)  # Core: 749, Interface: 2891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(input_wresults_df[\"effect\"], -input_wresults_df[\"elaspic_score\"])  # 0.5014374415058359 / 0.5573847932834505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(input_wresults_df[\"effect\"], -input_wresults_df[\"foldx_score\"])  # 0.4621773590138444 / 0.5118665337096965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(input_wresults_df[\"effect\"], input_wresults_df[\"provean_score\"])  # 0.4433472260225827 / 0.4561308022195954"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = input_wresults_df.copy()\n",
    "\n",
    "df[\"mutation_resnum\"] = df[\"mutation\"]\n",
    "df[\"mutation\"] = df[\"mutation_resnum\"].apply(lambda x: f\"{x[0]}{int(x[1:-1]) + 320}{x[-1]}\")\n",
    "df = df[[\"mutation\", \"elaspic_score\", \"provean_score\", \"foldx_score\"]]\n",
    "\n",
    "output_file = f\"07_benchmarks/elaspic-{DATASET_NAME}.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
