{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import socket\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import kmbio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from ev2.plugins.proteinsolver import (\n",
    "    ProteinSolver,\n",
    "    ProteinSolverAnalyzeError,\n",
    "    ProteinSolverBuildError,\n",
    ")\n",
    "from kmbio import PDB\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProteinSolver.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = Path(\"02_run_elaspic\").resolve()\n",
    "NOTEBOOK_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "NOTEBOOK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DATAPKG_OUTPUT_DIR\" in os.environ:\n",
    "    OUTPUT_DIR = Path(os.getenv(\"DATAPKG_OUTPUT_DIR\")).joinpath(\"elaspic-v2\").resolve()\n",
    "else:\n",
    "    OUTPUT_DIR = NOTEBOOK_DIR.parent\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (slurm_tmpdir := os.getenv(\"SLURM_TMPDIR\")) is not None:\n",
    "    os.environ[\"TMPDIR\"] = slurm_tmpdir\n",
    "    \n",
    "print(tempfile.gettempdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"scinet\" in socket.gethostname():\n",
    "    CPU_COUNT = 40\n",
    "else:\n",
    "    CPU_COUNT = max(1, len(os.sched_getaffinity(0)))\n",
    "\n",
    "CPU_COUNT = CPU_COUNT // 2\n",
    "\n",
    "CPU_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = os.getenv(\"DATASET_NAME\")\n",
    "TASK_ID = os.getenv(\"SLURM_ARRAY_TASK_ID\")\n",
    "TASK_COUNT = os.getenv(\"ORIGINAL_ARRAY_TASK_COUNT\") or os.getenv(\"SLURM_ARRAY_TASK_COUNT\")\n",
    "\n",
    "TASK_ID = int(TASK_ID) if TASK_ID is not None else None\n",
    "TASK_COUNT = int(TASK_COUNT) if TASK_COUNT is not None else None\n",
    "\n",
    "DATASET_NAME, TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = TASK_ID is None\n",
    "\n",
    "if DEBUG:\n",
    "    DATASET_NAME = \"starr-2020-core\"\n",
    "    TASK_ID = 1\n",
    "    TASK_COUNT = 1\n",
    "else:\n",
    "    assert DATASET_NAME is not None\n",
    "    assert TASK_ID is not None\n",
    "    assert TASK_COUNT is not None\n",
    "\n",
    "DATASET_NAME, TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = OUTPUT_DIR.joinpath(\"01_load_data\", f\"{DATASET_NAME}.parquet\")\n",
    "\n",
    "input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = pq.ParquetFile(input_file)\n",
    "\n",
    "pfile.num_row_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TASK_COUNT == pfile.num_row_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DF = pfile.read_row_group(TASK_ID - 1).to_pandas(integer_object_nulls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(INPUT_DF.head(2))\n",
    "print(len(INPUT_DF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = OUTPUT_DIR.joinpath(NOTEBOOK_DIR.name)\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "for row in INPUT_DF.itertuples():\n",
    "    for mutation, effect in zip(row.mutation, row.effect):\n",
    "        if pd.isnull(effect):\n",
    "            print(f\"Skipping mutation {mutation} because the effect is unknown ({effect}).\")\n",
    "            continue\n",
    "        input_data.append({\n",
    "            \"unique_id\": row.unique_id,\n",
    "            \"mutation\": mutation,\n",
    "            \"effect\": effect,\n",
    "            \"effect_type\": row.effect_type,\n",
    "        })\n",
    "\n",
    "input_df = pd.DataFrame(input_data)\n",
    "len(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET_NAME == \"starr-2020-core\":\n",
    "    elaspic_path = Path(\"/home/kimlab1/database_data/elaspic_v2/user_input/b3a357/.elaspic\").resolve(strict=True)\n",
    "elif DATASET_NAME == \"starr-2020-interface\":\n",
    "    elaspic_path = Path(\"/home/kimlab1/database_data/elaspic_v2/user_input/7cc10a/.elaspic\").resolve(strict=True)\n",
    "else:\n",
    "    raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_core = []\n",
    "results_interface = []\n",
    "\n",
    "for file in os.listdir(elaspic_path):\n",
    "    if file.startswith(\"mutation_\"):\n",
    "        mutation = file.split(\".\")[0].split(\"_\")[2]\n",
    "#         print(mutation, file)\n",
    "        with elaspic_path.joinpath(file).open(\"rt\") as fin:\n",
    "            data_list = json.load(fin)\n",
    "        for data in data_list:\n",
    "            assert mutation == data[\"mutation\"]\n",
    "            if \"idxs\" in data:\n",
    "                if DATASET_NAME.endswith(\"-core\"):\n",
    "                    continue\n",
    "                if data[\"idxs\"] != [0, 1]:\n",
    "                    print(f\"Skipping interaction {data}.\")\n",
    "                    continue\n",
    "                foldx_score_wt = float(data[\"analyse_complex_energy_wt\"].split(\",\")[0])\n",
    "                foldx_score_mut = float(data[\"analyse_complex_energy_mut\"].split(\",\")[0])\n",
    "                results_interface.append({\n",
    "                    \"mutation\": mutation,\n",
    "                    \"elaspic_score\": float(data[\"ddg\"]),\n",
    "                    \"provean_score\": float(data[\"provean_score\"]),\n",
    "                    \"foldx_score\": foldx_score_mut - foldx_score_wt,\n",
    "                })\n",
    "            else:\n",
    "                foldx_score_wt = float(data[\"stability_energy_wt\"].split(\",\")[0])\n",
    "                foldx_score_mut = float(data[\"stability_energy_mut\"].split(\",\")[0])\n",
    "                results_core.append({\n",
    "                    \"mutation\": mutation,\n",
    "                    \"elaspic_score\": float(data[\"ddg\"]),\n",
    "                    \"provean_score\": float(data[\"provean_score\"]),\n",
    "                    \"foldx_score\": foldx_score_mut - foldx_score_wt,\n",
    "\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_core_df = pd.DataFrame(results_core)\n",
    "\n",
    "len(results_core_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_interface_df = pd.DataFrame(results_interface, columns=results_core_df.columns)\n",
    "results_interface_df[\"provean_score\"] = results_interface_df[\"provean_score\"].fillna(np.nan)\n",
    "\n",
    "len(results_interface_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_core_df.merge(results_interface_df, on=[\"mutation\"], how=\"left\", suffixes=(\"_core\", \"_interface\"))\n",
    "\n",
    "results_df[\"elaspic_score\"] = [\n",
    "    ((elaspic_score_interface) if pd.notnull(elaspic_score_interface) else elaspic_score_core)\n",
    "    for elaspic_score_core, elaspic_score_interface\n",
    "    in results_df[[\"elaspic_score_core\", \"elaspic_score_interface\"]].values\n",
    "]\n",
    "\n",
    "# if results_df[\"provean_score_interface\"].notnull().any():\n",
    "#     assert np.allclose(results_df[\"provean_score_core\"].values, results_df[\"provean_score_interface\"].values, equal_nan=True)\n",
    "results_df[\"provean_score\"] = results_df[[\"provean_score_core\"]].mean(axis=1)\n",
    "\n",
    "results_df[\"foldx_score\"] = [\n",
    "    ((foldx_score_interface) if pd.notnull(foldx_score_interface) else foldx_score_core)\n",
    "    for foldx_score_core, foldx_score_interface\n",
    "    in results_df[[\"foldx_score_core\", \"foldx_score_interface\"]].values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wresults_df = input_df.merge(results_df, on=[\"mutation\"])\n",
    "len(input_wresults_df)  # Core: 749, Interface: 2891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.spearmanr(input_wresults_df[\"effect\"], -input_wresults_df[\"elaspic_score\"])  # 0.53153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.spearmanr(input_wresults_df[\"effect\"], -input_wresults_df[\"foldx_score\"])  # 0.4854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.spearmanr(input_wresults_df[\"effect\"], input_wresults_df[\"provean_score\"])  # 0.4741"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stats = {\n",
    "    # Core\n",
    "    (\"starr-2020-core\", \"elaspic_score\", \"core\"): -0.081719600581758,\n",
    "    (\"starr-2020-core\", \"foldx_score\", \"core\"): 0.48478755976010524,\n",
    "    (\"starr-2020-core\", \"provean_score\", \"core\"): 0.4261149009423275,\n",
    "    # Interface\n",
    "    (\"starr-2020-interface\", \"elaspic_score\", \"core\"): 0.5140238363135885,\n",
    "    (\"starr-2020-interface\", \"foldx_score\", \"core\"): 0.5294542669183915,\n",
    "    (\"starr-2020-interface\", \"provean_score\", \"core\"): 0.4133588948415616,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "for row in tqdm(INPUT_DF.itertuples(), total=len(INPUT_DF)):\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".pdb\") as tmp_file:\n",
    "        with open(tmp_file.name, \"wt\") as fout:\n",
    "            fout.write(row.protein_structure)\n",
    "        try:\n",
    "            data_core = ProteinSolver.build(tmp_file.name, row.protein_sequence, None)\n",
    "            if row.ligand_sequence is not None:\n",
    "                data_interface = ProteinSolver.build(\n",
    "                    tmp_file.name, row.protein_sequence, row.ligand_sequence\n",
    "                )\n",
    "            else:\n",
    "                data_interface = None\n",
    "        except ProteinSolverBuildError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "    _seen = set()\n",
    "    for idx in range(len(row.mutation)):\n",
    "        mutation = row.mutation[idx]\n",
    "        if mutation in _seen:\n",
    "            print(\n",
    "                f\"Already added mutation '{mutation}' for protein ({row.unique_id}, {row.dataset}, {row.name}).\"\n",
    "            )\n",
    "            continue\n",
    "        _seen.add(mutation)\n",
    "\n",
    "        aa = \"GVALICMFWPDESTYQNKRH\"\n",
    "        if re.search(f\"^[{aa}][1-9]+[0-9]*[{aa}]$\", mutation) is None:\n",
    "            print(f\"Skipping mutation {mutation} because it appears to be malformed.\")\n",
    "            continue\n",
    "\n",
    "        if mutation[0] == mutation[-1]:\n",
    "            print(f\"Skipping mutation {mutation} because the wildtype and mutant residues are the same.\")\n",
    "            continue\n",
    "\n",
    "        data_mut = {\n",
    "            \"unique_id\": row.unique_id,\n",
    "            \"mutation\": row.mutation[idx],\n",
    "            \"effect\": row.effect[idx],\n",
    "        }\n",
    "\n",
    "        tasks.append((data_core, data_interface, data_mut))\n",
    "\n",
    "len(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(input):\n",
    "    data_core, data_interface, data_mut = input\n",
    "    mutation = data_mut[\"mutation\"]\n",
    "    try:\n",
    "        results_core = ProteinSolver.analyze_mutation(f\"A_{mutation}\", data_core)\n",
    "        if data_interface is not None:\n",
    "            results_interface = ProteinSolver.analyze_mutation(f\"A_{mutation}\", data_interface)\n",
    "        else:\n",
    "            results_interface = {}\n",
    "    except ProteinSolverAnalyzeError as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    results = {\n",
    "        **data_mut,\n",
    "        **{f\"proteinsolver_core_{key}\": value for key, value in results_core.items()},\n",
    "        **{f\"proteinsolver_interface_{key}\": value for key, value in results_interface.items()},\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker(tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ProcessPoolExecutor(CPU_COUNT) as pool:\n",
    "    results = list(tqdm(pool.map(worker, tasks), total=len(tasks)))\n",
    "\n",
    "results_df = pd.DataFrame([l for l in results if l is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = output_dir.joinpath(f\"{DATASET_NAME}-{TASK_ID}-{TASK_COUNT}.parquet\")\n",
    "\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(pa.Table.from_pandas(results_df, preserve_index=False), output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
