{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Calculate features using [Rosetta's `cartesian_ddg` protocol](https://www.rosettacommons.org/docs/latest/cartesian-ddG).\n",
    "\n",
    "### Executing\n",
    "\n",
    "```bash\n",
    "DATASET_NAME=\"elaspic-training-set-core\" NOTEBOOK_PATH=\"$(realpath 02_run_rosetta_ddg.ipynb)\" sbatch --array=1-162 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "DATASET_NAME=\"protherm-dagger-core\" NOTEBOOK_PATH=\"$(realpath 02_run_rosetta_ddg.ipynb)\" sbatch --array=1-2 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "DATASET_NAME=\"rocklin-2017-core\" NOTEBOOK_PATH=\"$(realpath 02_run_rosetta_ddg.ipynb)\" sbatch --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "DATASET_NAME=\"elaspic-training-set-interface\" NOTEBOOK_PATH=\"$(realpath 02_run_rosetta_ddg.ipynb)\" sbatch --array=1-26 ../scripts/run_notebook_cpu.sh\n",
    "```\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import socket\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK_DIR = Path(\"02_run_rosetta_ddg\").resolve(strict=True)\n",
    "NOTEBOOK_DIR = Path(\"02_run_proteinsolver\").resolve(strict=True)\n",
    "# NOTEBOOK_DIR = Path(\"02_run_protbert\").resolve(strict=True)\n",
    "\n",
    "NOTEBOOK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DATAPKG_OUTPUT_DIR\" in os.environ:\n",
    "    OUTPUT_DIR = Path(os.getenv(\"DATAPKG_OUTPUT_DIR\")).joinpath(\"elaspic-v2\").resolve()\n",
    "else:\n",
    "    OUTPUT_DIR = NOTEBOOK_DIR.parent\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"elaspic-training-set-core\": 162,\n",
    "    \"protherm-dagger-core\": 2,\n",
    "    \"rocklin-2017-core\": 1,\n",
    "    \"elaspic-training-set-interface\": 26,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = OUTPUT_DIR.joinpath(NOTEBOOK_DIR.name)\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataset_name, task_count in datasets.items():\n",
    "    input_file = OUTPUT_DIR.joinpath(\"01_load_data\", f\"{dataset_name}.parquet\")\n",
    "    pfile = pq.ParquetFile(input_file)\n",
    "    assert task_count == pfile.num_row_groups, (task_count, pfile.num_row_groups)\n",
    "\n",
    "    missing = []\n",
    "    for task_id in range(1, task_count + 1):\n",
    "        if NOTEBOOK_DIR.name in [\"02_rosetta_ddg\"]:\n",
    "            output_file_wt2mut = output_dir.joinpath(f\"{dataset_name}-wt2mut-{task_id}-{task_count}.parquet\")\n",
    "            if not output_file_wt2mut.is_file():\n",
    "                missing.append(task_id)\n",
    "                continue\n",
    "            output_file_mut2wt = output_dir.joinpath(f\"{dataset_name}-mut2wt-{task_id}-{task_count}.parquet\")\n",
    "            if not output_file_mut2wt.is_file():\n",
    "                missing.append(task_id)\n",
    "        else:\n",
    "            output_file = output_dir.joinpath(f\"{dataset_name}-{task_id}-{task_count}.parquet\")\n",
    "            if not output_file.is_file():\n",
    "                missing.append(task_id)\n",
    "    print(f'{dataset_name}: {\",\".join(str(i) for i in missing)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
