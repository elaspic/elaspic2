{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Calculate features using [Rosetta's `cartesian_ddg` protocol](https://www.rosettacommons.org/docs/latest/cartesian-ddG).\n",
    "\n",
    "### Executing\n",
    "\n",
    "```bash\n",
    "DATASET_NAME=\"elaspic-training-set-core\" NOTEBOOK_PATH=\"$(realpath 02_run_rosetta_ddg.ipynb)\" sbatch --array=1-162 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "DATASET_NAME=\"protherm-dagger-core\" NOTEBOOK_PATH=\"$(realpath 02_run_rosetta_ddg.ipynb)\" sbatch --array=1-2 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "DATASET_NAME=\"rocklin-2017-core\" NOTEBOOK_PATH=\"$(realpath 02_run_rosetta_ddg.ipynb)\" sbatch --array=1-1 ../scripts/run_notebook_cpu.sh\n",
    "\n",
    "DATASET_NAME=\"elaspic-training-set-interface\" NOTEBOOK_PATH=\"$(realpath 02_run_rosetta_ddg.ipynb)\" sbatch --array=1-26 ../scripts/run_notebook_cpu.sh\n",
    "```\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import os\n",
    "import re\n",
    "import socket\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import kmbio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from ev2.plugins.modeller import Modeller\n",
    "from ev2.plugins.rosetta_ddg import RosettaDDG\n",
    "from kmbio import PDB\n",
    "from kmtools.structure_tools import DomainTarget\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = Path(\"02_run_rosetta_ddg\").resolve()\n",
    "NOTEBOOK_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "NOTEBOOK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DATAPKG_OUTPUT_DIR\" in os.environ:\n",
    "    OUTPUT_DIR = Path(os.getenv(\"DATAPKG_OUTPUT_DIR\")).joinpath(\"elaspic-v2\").resolve()\n",
    "else:\n",
    "    OUTPUT_DIR = NOTEBOOK_DIR.parent\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (slurm_tmpdir := os.getenv(\"SLURM_TMPDIR\")) is not None:\n",
    "    os.environ[\"TMPDIR\"] = slurm_tmpdir\n",
    "    \n",
    "print(tempfile.gettempdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"scinet\" in socket.gethostname():\n",
    "    CPU_COUNT = 40\n",
    "else:\n",
    "    CPU_COUNT = max(1, len(os.sched_getaffinity(0)))\n",
    "\n",
    "CPU_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = os.getenv(\"DATASET_NAME\")\n",
    "TASK_ID = os.getenv(\"SLURM_ARRAY_TASK_ID\")\n",
    "TASK_COUNT = os.getenv(\"ORIGINAL_ARRAY_TASK_COUNT\") or os.getenv(\"SLURM_ARRAY_TASK_COUNT\")\n",
    "\n",
    "TASK_ID = int(TASK_ID) if TASK_ID is not None else None\n",
    "TASK_COUNT = int(TASK_COUNT) if TASK_COUNT is not None else None\n",
    "\n",
    "DATASET_NAME, TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = TASK_ID is None\n",
    "\n",
    "if DEBUG:\n",
    "    DATASET_NAME = \"elaspic-training-set-interface\"\n",
    "    TASK_ID = 1\n",
    "    TASK_COUNT = 26\n",
    "else:\n",
    "    assert DATASET_NAME is not None\n",
    "    assert TASK_ID is not None\n",
    "    assert TASK_COUNT is not None\n",
    "\n",
    "DATASET_NAME, TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = OUTPUT_DIR.joinpath(\"01_load_data\", f\"{DATASET_NAME}.parquet\")\n",
    "\n",
    "input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = pq.ParquetFile(input_file)\n",
    "\n",
    "pfile.num_row_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TASK_COUNT == pfile.num_row_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DF = pfile.read_row_group(TASK_ID - 1).to_pandas(integer_object_nulls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(INPUT_DF.head(2))\n",
    "print(len(INPUT_DF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = OUTPUT_DIR.joinpath(NOTEBOOK_DIR.name)\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "for row in tqdm(INPUT_DF.itertuples(), total=len(INPUT_DF)):\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".pdb\") as tmp_file:\n",
    "        with open(tmp_file.name, \"wt\") as fout:\n",
    "            fout.write(row.protein_structure)\n",
    "        data = RosettaDDG.build(\n",
    "            tmp_file.name,\n",
    "            protocol=\"cartesian_ddg\",\n",
    "            energy_function=\"beta_nov16_cart\",\n",
    "            interface=0 if row.ligand_sequence is None else 1,\n",
    "        )\n",
    "\n",
    "    _seen = set()\n",
    "    for idx in range(len(row.mutation)):\n",
    "        mutation = row.mutation[idx]\n",
    "        if mutation in _seen:\n",
    "            print(\n",
    "                f\"Already added mutation '{mutation}' for protein ({row.unique_id}, {row.dataset}, {row.name}).\"\n",
    "            )\n",
    "            continue\n",
    "        _seen.add(mutation)\n",
    "\n",
    "        aa = \"GVALICMFWPDESTYQNKRH\"\n",
    "        if re.search(f\"^[{aa}][1-9]+[0-9]*[{aa}]$\", mutation) is None:\n",
    "            print(f\"Skipping mutation {mutation} because it appears to be malformed.\")\n",
    "            continue\n",
    "\n",
    "        data_mut = {\"unique_id\": row.unique_id, \"effect_type\": row.effect_type}\n",
    "        for column in [\"mutation\", \"effect\", \"provean_score\", \"foldx_score\", \"elaspic_score\"]:\n",
    "            if column in row._fields:\n",
    "                data_mut[column] = getattr(row, column)[idx]\n",
    "\n",
    "        tasks.append((data, data_mut, row.protein_sequence, row.ligand_sequence))\n",
    "\n",
    "len(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wildtype to mutant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_wt2mut(input):\n",
    "    data, data_mut, _, _ = input\n",
    "    mutation = data_mut[\"mutation\"]\n",
    "    try:\n",
    "        results = RosettaDDG.analyze_mutation(f\"A_{mutation}\", data)\n",
    "    except subprocess.CalledProcessError as error:\n",
    "        print(f\"Rosetta failed with an error ({error.returncode=}, {error.cmd=}, {error.output=}, {error.stderr=}).\")\n",
    "        return None\n",
    "    results = {f\"rosetta_{key}\": value for key, value in results.items()}\n",
    "    return {**data_mut, **results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ProcessPoolExecutor(CPU_COUNT) as pool:\n",
    "    results = list(tqdm(pool.map(worker_wt2mut, tasks), total=len(tasks)))\n",
    "\n",
    "results_wt2mut_df = pd.DataFrame([l for l in results if l is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_wt2mut = output_dir.joinpath(f\"{DATASET_NAME}-wt2mut-{TASK_ID}-{TASK_COUNT}.parquet\")\n",
    "\n",
    "output_file_wt2mut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(pa.Table.from_pandas(results_wt2mut_df, preserve_index=False), output_file_wt2mut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutant to wildtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_sequence(protein_sequence, mutation):\n",
    "    amino_acids = list(protein_sequence)\n",
    "    amino_acids[int(mutation[1:-1]) - 1] = mutation[-1]\n",
    "    protein_sequence_mut = \"\".join(amino_acids)\n",
    "    return protein_sequence_mut\n",
    "\n",
    "\n",
    "def create_model(structure_file, protein_sequence, ligand_sequence, mutation):\n",
    "    # Load structure (in order to remove warnings about loading pdb with use_auth_id)\n",
    "    unique_id = Path(structure_file).stem.partition(\".\")[0].rpartition(\"?\")[-1]\n",
    "    structure = kmbio.PDB.load(structure_file, bioassembly_id=True)\n",
    "    #\n",
    "    modeller_data = Modeller.build(structure)\n",
    "    protein_sequence_mut = mutate_sequence(protein_sequence, mutation)\n",
    "    target = DomainTarget(0, \"A\", protein_sequence, None, None, protein_sequence_mut)\n",
    "\n",
    "    domains = [target]\n",
    "    if ligand_sequence is not None:\n",
    "        domains.append(DomainTarget(0, \"B\", ligand_sequence, None, None, ligand_sequence))\n",
    "\n",
    "    structure_bm, results = Modeller.create_model(domains, modeller_data)\n",
    "    structure_file_mut = structure_file.parent.joinpath(f\"{structure_file.stem}-{mutation}.pdb\")\n",
    "    PDB.save(structure_bm, structure_file_mut)\n",
    "    return structure_file_mut\n",
    "\n",
    "\n",
    "def worker_mut2wt(input):\n",
    "    data, data_mut, protein_sequence, ligand_sequence = input\n",
    "    mutation = data_mut[\"mutation\"]\n",
    "    mutation_rev = mutation[-1] + mutation[1:-1] + mutation[0]\n",
    "    # Mutate model\n",
    "    structure_file_mut = create_model(\n",
    "        Path(data.structure_file), protein_sequence, ligand_sequence, mutation\n",
    "    )\n",
    "    data = data._replace(structure_file=structure_file_mut.as_posix())\n",
    "    # Update mutation data\n",
    "    data_mut[\"mutation\"] = mutation_rev\n",
    "    for key, value in data_mut.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            data_mut[key] = -value\n",
    "    return worker_wt2mut((data, data_mut, protein_sequence, ligand_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worker_mut2wt(tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ProcessPoolExecutor(CPU_COUNT) as pool:\n",
    "    results = list(tqdm(pool.map(worker_mut2wt, tasks), total=len(tasks)))\n",
    "\n",
    "results_mut2wt_df = pd.DataFrame([l for l in results if l is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_mut2wt = output_dir.joinpath(f\"{DATASET_NAME}-mut2wt-{TASK_ID}-{TASK_COUNT}.parquet\")\n",
    "\n",
    "output_file_mut2wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(pa.Table.from_pandas(results_mut2wt_df, preserve_index=False), output_file_mut2wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
