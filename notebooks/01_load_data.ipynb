{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "This notebook should be run on a machine with > 32G of memory.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import crc32c\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = \"01_load_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/kimlab4/strokach/workspace/elaspic2/notebooks/01_load_data')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOTEBOOK_DIR = Path(NOTEBOOK_NAME).resolve()\n",
    "NOTEBOOK_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "NOTEBOOK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/kimlab1/database_data/datapkg_output_dir')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if \"DATAPKG_OUTPUT_DIR\" in os.environ:\n",
    "    DATAPKG_OUTPUT_DIR = Path(os.getenv(\"DATAPKG_OUTPUT_DIR\")).resolve()\n",
    "else:\n",
    "    DATAPKG_OUTPUT_DIR = NOTEBOOK_DIR\n",
    "DATAPKG_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "DATAPKG_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/kimlab1/database_data/datapkg_output_dir/elaspic2')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if \"DATAPKG_OUTPUT_DIR\" in os.environ:\n",
    "    OUTPUT_DIR = Path(os.getenv(\"DATAPKG_OUTPUT_DIR\")).joinpath(\"elaspic2\").resolve()\n",
    "else:\n",
    "    OUTPUT_DIR = NOTEBOOK_DIR.parent\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources = {\n",
    "    # === Core ===\n",
    "    \"elaspic-training-set-core\": DATAPKG_OUTPUT_DIR.joinpath(\n",
    "        \"elaspic-training-set\", \"02_export_data_core\", \"elaspic-training-set-core.parquet\"\n",
    "    ),\n",
    "    \"protherm-dagger-core\": DATAPKG_OUTPUT_DIR.joinpath(\n",
    "        \"protein-folding-energy\", \"protherm_dagger\", \"mutation-by-sequence.parquet\"\n",
    "    ),\n",
    "    \"rocklin-2017-core\": DATAPKG_OUTPUT_DIR.joinpath(\n",
    "        \"protein-folding-energy\", \"rocklin_2017\", \"mutation-ssm2.parquet\"\n",
    "    ),\n",
    "    \"dunham-2020-core\": DATAPKG_OUTPUT_DIR.joinpath(\n",
    "        \"protein-folding-energy\", \"dunham_2020_tianyu\", \"monomers.parquet\"\n",
    "    ),\n",
    "    \"starr-2020-core\": DATAPKG_OUTPUT_DIR.joinpath(\n",
    "        \"protein-folding-energy\", \"starr_2020_domain\", \"stability.parquet\"\n",
    "    ),\n",
    "    \"cagi5-frataxin-core\": DATAPKG_OUTPUT_DIR.joinpath(\n",
    "        \"protein-folding-energy\", \"cagi5_frataxin\", \"1ekg-ddg.parquet\"\n",
    "    ),\n",
    "    \"huang-2020-core\": DATAPKG_OUTPUT_DIR.joinpath(\n",
    "        \"protein-folding-energy\", \"huang_2020\", \"2jie-ddg.parquet\"\n",
    "    ),\n",
    "    # === Interface ===\n",
    "    \"elaspic-training-set-interface\": DATAPKG_OUTPUT_DIR.joinpath(\n",
    "        \"elaspic-training-set\", \"02_export_data_interface\", \"elaspic-training-set-interface.parquet\"\n",
    "    ),\n",
    "    \"skempi-v2-interface\": DATAPKG_OUTPUT_DIR.joinpath(\n",
    "        \"protein-folding-energy\", \"skempi_v2\", \"skempi-v2.parquet\"\n",
    "    ),\n",
    "    # \"intact-mutations-interface\": DATAPKG_OUTPUT_DIR.joinpath(\n",
    "    #     \"protein-folding-energy\", \"intact_mutations\", \"intact-mutations.parquet\"\n",
    "    # ),\n",
    "    \"dunham-2020-interface\": DATAPKG_OUTPUT_DIR.joinpath(\n",
    "        \"protein-folding-energy\", \"dunham_2020_tianyu\", \"dimers.parquet\"\n",
    "    ),\n",
    "    \"starr-2020-interface\": DATAPKG_OUTPUT_DIR.joinpath(\n",
    "        \"protein-folding-energy\", \"starr_2020_domain\", \"affinity.parquet\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_group_sizes = {\n",
    "    \"dunham-2020-core\": 1,\n",
    "    \"dunham-2020-interface\": 1,\n",
    "    \"starr-2020-core\": 1,\n",
    "    \"starr-2020-interface\": 1,\n",
    "    \"huang-2020-core\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, path in resources.items():\n",
    "    assert Path(path).is_file(), path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"unique_id\",\n",
    "    \"dataset\",\n",
    "    \"name\",\n",
    "    \"protein_sequence\",\n",
    "    \"ligand_sequence\",\n",
    "    \"mutation\",\n",
    "    \"effect\",\n",
    "    \"effect_type\",\n",
    "    \"protein_structure\",\n",
    "]\n",
    "\n",
    "extra_columns = [\n",
    "    \"provean_score\",\n",
    "    \"foldx_score\",\n",
    "    \"elaspic_score\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_id(dataset, effect_type, protein_sequence, ligand_sequence):\n",
    "    if ligand_sequence is not None:\n",
    "        key = f\"{dataset}|{effect_type}|{protein_sequence}|{ligand_sequence}\"\n",
    "    else:\n",
    "        key = f\"{dataset}|{effect_type}|{protein_sequence}\"\n",
    "    return crc32c.crc32c(key.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_id_2(dataset, name, effect_type, protein_sequence, ligand_sequence):\n",
    "    if ligand_sequence is not None:\n",
    "        key = f\"{dataset}|{name}|{effect_type}|{protein_sequence}|{ligand_sequence}\"\n",
    "    else:\n",
    "        key = f\"{dataset}|{name}|{effect_type}|{protein_sequence}\"\n",
    "    return crc32c.crc32c(key.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/kimlab1/database_data/datapkg_output_dir/elaspic2/01_load_data')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = OUTPUT_DIR.joinpath(NOTEBOOK_NAME).resolve()\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elaspic-training-set-core\n",
      "Read 50429 rows.\n",
      "Removing 11530 rows with fewer than two mutations.\n",
      "Removing 22710 rows with fewer than two unique effects.\n",
      "\n",
      "protherm-dagger-core\n",
      "Read 173 rows.\n",
      "Removing 57 rows with fewer than two mutations.\n",
      "Removing 1 rows with fewer than two unique effects.\n",
      "\n",
      "rocklin-2017-core\n",
      "Read 14 rows.\n",
      "Removing 0 rows with fewer than two mutations.\n",
      "Removing 0 rows with fewer than two unique effects.\n",
      "\n",
      "dunham-2020-core\n",
      "Read 12 rows.\n",
      "Removing 0 rows with fewer than two mutations.\n",
      "Removing 0 rows with fewer than two unique effects.\n",
      "\n",
      "starr-2020-core\n",
      "Read 1 rows.\n",
      "Removing 0 rows with fewer than two mutations.\n",
      "Removing 0 rows with fewer than two unique effects.\n",
      "\n",
      "cagi5-frataxin-core\n",
      "Read 1 rows.\n",
      "Removing 0 rows with fewer than two mutations.\n",
      "Removing 0 rows with fewer than two unique effects.\n",
      "\n",
      "huang-2020-core\n",
      "Read 1 rows.\n",
      "Removing 0 rows with fewer than two mutations.\n",
      "Removing 0 rows with fewer than two unique effects.\n",
      "\n",
      "elaspic-training-set-interface\n",
      "Read 30191 rows.\n",
      "Removing 13910 rows with fewer than two mutations.\n",
      "Removing 13718 rows with fewer than two unique effects.\n",
      "\n",
      "skempi-v2-interface\n",
      "Read 335 rows.\n",
      "Removing 116 rows with fewer than two mutations.\n",
      "Removing 0 rows with fewer than two unique effects.\n",
      "\n",
      "dunham-2020-interface\n",
      "Read 8 rows.\n",
      "Removing 0 rows with fewer than two mutations.\n",
      "Removing 0 rows with fewer than two unique effects.\n",
      "\n",
      "starr-2020-interface\n",
      "Read 1 rows.\n",
      "Removing 0 rows with fewer than two mutations.\n",
      "Removing 0 rows with fewer than two unique effects.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_seen = {\n",
    "    \"core\": set(),\n",
    "    \"interface\": set(),\n",
    "}\n",
    "\n",
    "for dataset_name, dataset_file in resources.items():\n",
    "    print(dataset_name)\n",
    "\n",
    "    coi = dataset_name.rsplit(\"-\", 1)[-1]\n",
    "    assert coi in [\"core\", \"interface\"]\n",
    "\n",
    "    df = (\n",
    "        pq.read_table(dataset_file)\n",
    "        .to_pandas(integer_object_nulls=True)\n",
    "        .rename(columns={\"mutations\": \"mutation\"})\n",
    "    )\n",
    "    print(f\"Read {len(df)} rows.\")\n",
    "\n",
    "    # Remove unneeded data\n",
    "    mask = df[\"mutation\"].apply(len) >= 2\n",
    "    print(f\"Removing {(~mask).sum()} rows with fewer than two mutations.\")\n",
    "    df = df[mask]\n",
    "\n",
    "    mask = df[\"effect\"].apply(lambda x: len(set(x))) >= 2\n",
    "    print(f\"Removing {(~mask).sum()} rows with fewer than two unique effects.\")\n",
    "    df = df[mask]\n",
    "\n",
    "    if \"dataset\" not in df:\n",
    "        df[\"dataset\"] = dataset_name\n",
    "    if \"ligand_sequence\" not in df:\n",
    "        df[\"ligand_sequence\"] = None\n",
    "\n",
    "    # Add a unique id\n",
    "\n",
    "    df[\"unique_id\"] = [\n",
    "        get_unique_id(dataset, effect_type, protein_sequence, ligand_sequence)\n",
    "        for dataset, effect_type, protein_sequence, ligand_sequence in df[\n",
    "            [\"dataset\", \"effect_type\", \"protein_sequence\", \"ligand_sequence\"]\n",
    "        ].values\n",
    "    ]\n",
    "    unique_ids = set(df[\"unique_id\"].values)\n",
    "    if len(unique_ids) != len(df):\n",
    "        df[\"unique_id\"] = [\n",
    "            get_unique_id_2(dataset, name, effect_type, protein_sequence, ligand_sequence)\n",
    "            for dataset, name, effect_type, protein_sequence, ligand_sequence in df[\n",
    "                [\"dataset\", \"name\", \"effect_type\", \"protein_sequence\", \"ligand_sequence\"]\n",
    "            ].values\n",
    "        ]\n",
    "        unique_ids = set(df[\"unique_id\"].values)\n",
    "    assert len(unique_ids) == len(df)\n",
    "    assert not set(unique_ids) & _seen[coi]\n",
    "    _seen[coi].update(unique_ids)\n",
    "\n",
    "    columns_all = columns + [c for c in extra_columns if c in df]\n",
    "    df_out = df[columns_all]\n",
    "\n",
    "    # Write output\n",
    "    output_file = output_dir.joinpath(f\"{dataset_name}.parquet\")\n",
    "#     if output_file.is_file():\n",
    "#         print(f\"Refusing to overwrite existing file: {output_file}.\\n\")\n",
    "#         continue\n",
    "    pq.write_table(\n",
    "        pa.Table.from_pandas(df_out, preserve_index=False),\n",
    "        output_file,\n",
    "        row_group_size=row_group_sizes.get(dataset_name, 100),\n",
    "    )\n",
    "    del df, df_out\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
