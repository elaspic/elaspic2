{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shlex\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import lightgbm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DATAPKG_OUTPUT_DIR\" in os.environ:\n",
    "    OUTPUT_DIR = Path(os.getenv(\"DATAPKG_OUTPUT_DIR\")).joinpath(\"elaspic-v2\").resolve()\n",
    "else:\n",
    "    OUTPUT_DIR = NOTEBOOK_DIR.parent\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (slurm_tmpdir := os.getenv(\"SLURM_TMPDIR\")) is not None:\n",
    "    os.environ[\"TMPDIR\"] = slurm_tmpdir\n",
    "    \n",
    "print(tempfile.gettempdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "#     \"elaspic-training-set-core\",\n",
    "#     \"protherm-dagger-core\",\n",
    "#     \"rocklin-2017-core\",\n",
    "    \"elaspic-training-set-interface\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_generators = [\n",
    "    \"02_run_rosetta_ddg\",\n",
    "    \"02_run_proteinsolver\",\n",
    "    \"02_run_protbert\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_mutations(df):\n",
    "    results =[]\n",
    "    for row in df.itertuples():\n",
    "        for idx in range(len(row.mutation)):\n",
    "            row_mut = {\n",
    "                \"unique_id\": row.unique_id,\n",
    "                \"dataset\": row.dataset,\n",
    "                'name': row.name,\n",
    "                \"mutation\": row.mutation[idx],\n",
    "                \"effect\": row.effect[idx],\n",
    "                \"effect_type\": row.effect_type,\n",
    "            }\n",
    "            for column in [\"provean_score\", \"foldx_score\", \"elaspic_score\"]:\n",
    "                if hasattr(row, column):\n",
    "                    row_mut[column] = getattr(row, column)[idx]\n",
    "            results.append(row_mut)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mutation_complement(df):\n",
    "    df_in = df\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"mutation\"] = df[\"mutation\"].str[-1] + df[\"mutation\"].str[1:-1] + df[\"mutation\"].str[0]\n",
    "    for column in [\"effect\", \"provean_score\", \"foldx_score\", \"elaspic_score\"]:\n",
    "        if column in df:\n",
    "            df[column] = -df[column]\n",
    "    for column in df:\n",
    "        if column.endswith(\"_wt\"):\n",
    "            column_mut = column[:-3] + \"_mut\" \n",
    "            df[column], df[column_mut] = df[column_mut].copy(), df[column].copy()\n",
    "    \n",
    "    df_out = pd.concat([df_in, df], ignore_index=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame([\n",
    "    [0, \"M1A\", 1.234, \"wt score\", \"mut score\"],\n",
    "    [1, \"M2C\", -0.05, \"wt score 2\", \"mut score 2\"]\n",
    "], columns=[\"unique_id\", \"mutation\", \"effect\", \"feature_wt\", \"feature_mut\"])\n",
    "\n",
    "tmp2_df = add_mutation_complement(tmp_df)\n",
    "\n",
    "display(tmp_df)\n",
    "display(tmp2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in datasets:\n",
    "    input_file = OUTPUT_DIR.joinpath(\"01_load_data\", f\"{dataset_name}.parquet\")\n",
    "    pfile = pq.ParquetFile(input_file)\n",
    "    task_count = pfile.num_row_groups\n",
    "    df = pfile.read().to_pandas(integer_object_nulls=True)\n",
    "    expanded_df = (\n",
    "        add_mutation_complement(expand_mutations(df))\n",
    "        .drop_duplicates(subset=[\"unique_id\", \"mutation\"])\n",
    "        .sort_values([\"unique_id\", \"mutation\"])\n",
    "    )\n",
    "    sequence_df = df[[\"unique_id\", \"protein_sequence\", \"ligand_sequence\"]].drop_duplicates()\n",
    "\n",
    "    features = {}\n",
    "    for feature_generator in feature_generators:\n",
    "        output_dir = OUTPUT_DIR.joinpath(feature_generator)\n",
    "        feature_dfs = []\n",
    "        for task_id in range(1, task_count + 1):\n",
    "            if feature_generator in  [\"02_run_rosetta_ddg\"]:\n",
    "                #\n",
    "                output_file_wt2mut = output_dir.joinpath(f\"{dataset_name}-wt2mut-{task_id}-{task_count}.parquet\")\n",
    "                if not output_file_wt2mut.is_file():\n",
    "                    print(f\"File {output_file_wt2mut} is missing. Skipping...\")\n",
    "                    continue\n",
    "                feature_wt2mut_df = pq.read_table(output_file_wt2mut).to_pandas(integer_object_nulls=True)\n",
    "                feature_dfs.append(feature_wt2mut_df)\n",
    "                \n",
    "                #\n",
    "                output_file_mut2wt = output_dir.joinpath(f\"{dataset_name}-mut2wt-{task_id}-{task_count}.parquet\")\n",
    "                if not output_file_mut2wt.is_file():\n",
    "                    print(f\"File {output_file_mut2wt} is missing. Skipping...\")\n",
    "                    continue\n",
    "                feature_mut2wt_df = pq.read_table(output_file_mut2wt).to_pandas(integer_object_nulls=True)\n",
    "                feature_mut2wt_df[\"unique_id\"] = -feature_mut2wt_df[\"unique_id\"]\n",
    "                feature_dfs.append(feature_mut2wt_df)\n",
    "            else:\n",
    "                output_file = output_dir.joinpath(f\"{dataset_name}-{task_id}-{task_count}.parquet\")\n",
    "                if not output_file.is_file():\n",
    "                    print(f\"File {output_file} is missing. Skipping...\")\n",
    "                    continue\n",
    "                feature_df = pq.read_table(output_file).to_pandas(integer_object_nulls=True)\n",
    "                feature_df = add_mutation_complement(feature_df)\n",
    "                feature_dfs.append(feature_df)\n",
    "\n",
    "        feature_df = pd.concat(feature_dfs, ignore_index=True)\n",
    "        features[feature_generator] = feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_feature_dfs(feature_dfs):\n",
    "    def _clean_df(df):\n",
    "        df = df.copy()\n",
    "        assert len(df) == len(df[[\"unique_id\", \"mutation\"]].drop_duplicates())\n",
    "        for column in [\"effect\", \"effect_type\", \"provean_score\", \"foldx_score\", \"elaspic_score\"]:\n",
    "            if column in df:\n",
    "                del df[column]\n",
    "        return df\n",
    "\n",
    "    df = _clean_df(feature_dfs[0])\n",
    "    for other_df in feature_dfs[1:]:\n",
    "        df = df.merge(_clean_df(other_df), how=\"outer\", on=[\"unique_id\", \"mutation\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features_df = merge_feature_dfs(list(features.values())).sort_values([\"unique_id\", \"mutation\"])\n",
    "assert merged_features_df[\"unique_id\"].min() >= 0\n",
    "\n",
    "len(merged_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features_nonan_df = merged_features_df.dropna()\n",
    "print(f\"Lost {len(merged_features_df) - len(merged_features_nonan_df):,} out of {len(merged_features_df):,} rows due to missing values.\")\n",
    "\n",
    "len(merged_features_nonan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = expanded_df.merge(merged_features_nonan_df, on=[\"unique_id\", \"mutation\"], validate=\"1:1\")\n",
    "assert len(final_df) == len(merged_features_nonan_df)\n",
    "print(f\"Lost {len(expanded_df) - len(final_df):,} out of {len(expanded_df):,} rows due to missing features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df) , len(merged_features_nonan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(final_df.head())\n",
    "print(len(final_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not final_df[\"foldx_score\"].isnull().any()\n",
    "assert not final_df[\"effect\"].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"effect_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# df = final_df[final_df[\"effect_type\"] == \"Deleteriousness class\"].dropna()\n",
    "df = final_df[final_df[\"effect_type\"] == \"ΔΔG\"]\n",
    "\n",
    "stats.spearmanr(df[\"effect\"], df[\"rosetta_bind_dg_change\"])\n",
    "stats.spearmanr(df[\"effect\"], df[\"rosetta_bind_dg_change\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_clusters(input_sequences, min_seq_id=0.3):\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        input_dir = Path(tmp_dir, \"input\")\n",
    "        input_dir.mkdir()\n",
    "        \n",
    "        output_dir = Path(tmp_dir, \"output\")\n",
    "        output_dir.mkdir()\n",
    "        \n",
    "        scratch_dir = Path(tmp_dir, \"scratch\")\n",
    "        scratch_dir.mkdir()\n",
    "        \n",
    "        with input_dir.joinpath(\"input.fasta\").open(\"wt\") as fout:\n",
    "            for tup in input_sequences.itertuples():\n",
    "                fout.write(f\">{tup.unique_id}\\n{tup.protein_sequence}\\n\")\n",
    "        \n",
    "        system_command = f\"mmseqs easy-cluster --min-seq-id {min_seq_id} '{input_dir}/input.fasta' '{output_dir}/result' '{scratch_dir}'\"\n",
    "        print(system_command)\n",
    "        \n",
    "        proc = subprocess.run(shlex.split(system_command), capture_output=True, check=True)\n",
    "        \n",
    "        cluster_df = pd.read_csv(output_dir.joinpath(\"result_cluster.tsv\"), sep=\"\\t\", names=[\"cluster_id\", \"unique_id\"])\n",
    "        assert len(cluster_df) == len(cluster_df[\"unique_id\"].unique())\n",
    "\n",
    "    return cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = sequence_df.merge(final_df[[\"unique_id\"]].drop_duplicates())\n",
    "\n",
    "len(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = obtain_clusters(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"cluster_id\" in final_df:\n",
    "    del final_df[\"cluster_id\"]\n",
    "\n",
    "final_df = final_df.merge(cluster_df, on=\"unique_id\", how=\"outer\", validate=\"m:1\")\n",
    "assert final_df[\"cluster_id\"].notnull().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold, PredefinedSplit\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    \"unique_id\", \"dataset\", \"name\", \"mutation\", \"effect\", \"effect_type\", \"foldx_score\", \"provean_score\", \"elaspic_score\", \"cluster_id\",\n",
    "    \"test_fold\",\n",
    "]\n",
    "\n",
    "columns_to_drop += [\n",
    "    \"rosetta_opt_apart_dg_change\",\n",
    "    \"rosetta_apart_dg_change\",\n",
    "    \"rosetta_complex_dg_change\",\n",
    "    \"rosetta_opt_bind_dg_change\",\n",
    "    \"rosetta_bind_dg_change\",\n",
    "]\n",
    "\n",
    "tup = next(final_df.itertuples())\n",
    "columns_to_drop += [\n",
    "    field for field in tup._fields if isinstance(getattr(tup, field), (list, tuple, np.ndarray))\n",
    "]\n",
    "columns_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group(df):\n",
    "    vc = df[\"unique_id\"].value_counts()\n",
    "    groups = np.array([vc[uid] for uid in df[\"unique_id\"].unique()])\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_columns = [\n",
    "    \"unique_id\", \"dataset\", \"name\", \"mutation\", \"effect_type\", \"effect\", \n",
    "]\n",
    "\n",
    "eval_columns = [\n",
    "    \"ddg_pred\",\n",
    "    \"provean_score\",\n",
    "    \"foldx_score\",\n",
    "    \"elaspic_score\",\n",
    "    \"rosetta_opt_apart_dg_change\",\n",
    "    \"rosetta_apart_dg_change\",\n",
    "    \"rosetta_complex_dg_change\",\n",
    "    \"rosetta_opt_bind_dg_change\",\n",
    "    \"rosetta_bind_dg_change\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any\n",
    "\n",
    "def map_to_test_fold(df):\n",
    "\n",
    "    @dataclass(order=True)\n",
    "    class PrioritizedItem:\n",
    "        priority: int\n",
    "        idx: int=field(compare=False)\n",
    "        data: Any=field(compare=False)\n",
    "\n",
    "    ddg_df = df[df[\"effect_type\"] == \"ΔΔG\"]\n",
    "    other_df = df[df[\"effect_type\"] != \"ΔΔG\"]\n",
    "    assert len(ddg_df) + len(other_df) == len(df)\n",
    "    \n",
    "    ddg_pq = [PrioritizedItem(0, i, []) for i in range(10)]\n",
    "    for cluster_id, gp in ddg_df.groupby(\"cluster_id\"):\n",
    "        item = heapq.heappop(ddg_pq)\n",
    "        item.priority += len(gp)\n",
    "        item.data.append(cluster_id)\n",
    "        heapq.heappush(ddg_pq, item)\n",
    "    \n",
    "    mapping = {}\n",
    "    for item in ddg_pq:\n",
    "        for cluster_id in item.data:\n",
    "            mapping[cluster_id] = item.idx\n",
    "    \n",
    "    del ddg_pq\n",
    "    \n",
    "    other_pq = [PrioritizedItem(0, i, []) for i in range(10)]\n",
    "    for cluster_id, gp in other_df.groupby(\"cluster_id\"):\n",
    "        if cluster_id in mapping:\n",
    "            item_idx = mapping[cluster_id]\n",
    "            item = next(item for item in other_pq if item.idx == item_idx)\n",
    "            item.priority += len(gp)\n",
    "            item.data.append(cluster_id)\n",
    "            heapq.heapify(other_pq)\n",
    "        else:\n",
    "            item = heapq.heappop(other_pq)\n",
    "            item.priority += len(gp)\n",
    "            item.data.append(cluster_id)\n",
    "            heapq.heappush(other_pq, item)\n",
    "\n",
    "    for item in other_pq:\n",
    "        for cluster_id in item.data:\n",
    "            if cluster_id in mapping:\n",
    "                assert mapping[cluster_id] == item.idx\n",
    "            else:\n",
    "                mapping[cluster_id] = item.idx\n",
    "                \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id_to_test_fold_mapping = map_to_test_fold(final_df)\n",
    "final_df[\"test_fold\"] = final_df[\"cluster_id\"].map(cluster_id_to_test_fold_mapping)\n",
    "assert final_df[\"test_fold\"].notnull().all()\n",
    "assert len(final_df[\"test_fold\"].unique()) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(df):\n",
    "    effect = df[\"effect\"].values\n",
    "    effect[df[\"effect_type\"] != \"ΔΔG\"] *= 3\n",
    "    effect = np.clip(effect, -5, 5) * 1000 + 5000\n",
    "    return effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    #\n",
    "    \"objective\": \"lambdarank\",\n",
    "#     \"objective\": \"rank_xendcg\",\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"eval_at\": 1_000_000,\n",
    "    \"label_gain\": [(np.log2(i + 1) + 1) for i in range(0, 10_001)],\n",
    "    #\n",
    "    \"max_bin\": 255,\n",
    "#     \"num_trees\": 100,  # aka num_boost_round\n",
    "    \"learning_rate\": 0.1,\n",
    "}\n",
    "\n",
    "result_dfs = []\n",
    "\n",
    "ps = PredefinedSplit(final_df[\"test_fold\"])\n",
    "for train, test in ps.split():\n",
    "    train_df = final_df.iloc[train].copy()\n",
    "    test_df = final_df.iloc[test].copy()\n",
    "    assert not set(train_df[\"cluster_id\"]) & set(test_df[\"cluster_id\"])\n",
    "\n",
    "    train_ds = lgb.Dataset(\n",
    "        train_df.drop(columns_to_drop, axis=1),\n",
    "        label=get_label(train_df),\n",
    "        group=get_group(train_df),\n",
    "    )\n",
    "\n",
    "    valid_ds = lgb.Dataset(\n",
    "        test_df.drop(columns_to_drop, axis=1),\n",
    "        label=get_label(test_df),\n",
    "        group=get_group(test_df),\n",
    "        reference=train_ds,\n",
    "    )\n",
    "    \n",
    "    bst = lgb.train(param, train_ds, num_boost_round=100, valid_sets=[valid_ds], verbose_eval=10000)\n",
    "    \n",
    "    test_df[\"ddg_pred\"] = bst.predict(test_df.drop(columns_to_drop, axis=1), num_iteration=bst.best_iteration)\n",
    "    result_dfs.append(test_df[key_columns + eval_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(result_dfs, ignore_index=True)\n",
    "result_df[\"provean_score\"] = -result_df[\"provean_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_spearman_stats(df, feature_columns, target_column):\n",
    "    df = df.dropna(subset=feature_columns + [target_column])\n",
    "    for column in feature_columns:\n",
    "        corr = stats.spearmanr(df[column], df[target_column])\n",
    "        print(f\"{column:30s} {corr[0]:+.4} {corr[1]:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spearman_stats(result_df, eval_columns, \"effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_spearman_stats(result_df[result_df[\"effect_type\"] == \"ΔΔG\"], eval_columns, \"effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_sequence_stats(df, feature_columns, target_column, min_gp_size=6):\n",
    "    df = df.dropna(subset=feature_columns + [target_column])\n",
    "    results = {c: [] for c in feature_columns}\n",
    "    for _, gp in df.groupby(\"unique_id\"):\n",
    "        if len(gp) < min_gp_size:\n",
    "            continue\n",
    "        for column in feature_columns:\n",
    "            corr = stats.spearmanr(gp[column], gp[target_column])\n",
    "            results[column].append(corr[0])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_sequence_stats = compute_per_sequence_stats(result_df, eval_columns, \"effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, ax = plt.subplots()\n",
    "\n",
    "out = ax.boxplot(per_sequence_stats.values())\n",
    "_ = ax.set_xticklabels(per_sequence_stats.keys(), rotation=\"vertical\")\n",
    "# ax.set_ylim(-1, 1)\n",
    "# fg.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_sequence_stats_ddg = compute_per_sequence_stats(\n",
    "    result_df[result_df[\"effect_type\"] == \"ΔΔG\"],\n",
    "    eval_columns,\n",
    "    \"effect\",\n",
    "    18\n",
    ")\n",
    "\n",
    "fg, ax = plt.subplots()\n",
    "\n",
    "out = ax.boxplot(per_sequence_stats_ddg.values())\n",
    "_ = ax.set_xticklabels(per_sequence_stats_ddg.keys(), rotation=\"vertical\")\n",
    "# ax.set_ylim(-1, 1)\n",
    "# fg.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_sequence_stats_ddg = compute_per_sequence_stats(\n",
    "    result_df[result_df[\"effect_type\"] == \"ΔΔG\"],\n",
    "    eval_columns,\n",
    "    \"effect\",\n",
    "    2\n",
    ")\n",
    "\n",
    "fg, ax = plt.subplots()\n",
    "\n",
    "out = ax.boxplot(per_sequence_stats_ddg.values())\n",
    "_ = ax.set_xticklabels(per_sequence_stats_ddg.keys(), rotation=\"vertical\")\n",
    "# ax.set_ylim(-1, 1)\n",
    "# fg.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = ['r', 'g', 'b', 'y']\n",
    "for x, val, c in zip(xs, vals, palette):\n",
    "    plt.scatter(x, val, alpha=0.4, color=c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[(train_df[\"effect\"] * 1_000).astype(np.int) > 300_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = plt.hist(final_df[\"effect\"], bins=100, range=(-5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"ndcg_eval_at\": 1000000000000,\n",
    "    \"max_bin\": 255,\n",
    "}\n",
    "\n",
    "\n",
    "bst = lgb.train(param, train_ds, num_boost_round=100, valid_sets=[valid_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = bst.predict(test_df.drop(columns_to_drop, axis=1), num_iteration=bst.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = bst.predict(test_df.drop(columns_to_drop, axis=1), num_iteration=bst.best_iteration)\n",
    "test_df = test_df.copy()\n",
    "test_df[\"ddg_pred\"] = ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(test_df[\"effect\"], test_df[\"ddg_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(test_df[\"effect\"], test_df[\"foldx_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(test_df[\"effect\"], test_df[\"provean_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
