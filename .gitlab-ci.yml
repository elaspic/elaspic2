default:
  image: condaforge/linux-anvil-comp7:latest

stages:
  - custom
  - lint
  - build
  - test
  - doc
  - deploy

# === Variables ===

variables:
  PACKAGE_VERSION: "0.1.0"

.py37: &py37
  PYTHON_VERSION: "3.7"

.py38: &py38
  PYTHON_VERSION: "3.8"

# === Configurations ===

.skip-custom-pipelines:
  except:
    variables:
      - $UPDATE_PAGES

.configure:
  extends:
    - .skip-custom-pipelines
  before_script:
    # Set conda envs and pkgs dirs
    - |
      cat <<EOF > ~/.condarc
      channel_priority: true
      channels:
        - pytorch
        - conda-forge
        - defaults
        - kimlab
        - ostrokach-forge
        - bioconda
        - salilab
        - omnia
      EOF

# === Playground ===

create-conda-env:
  stage: lint
  image: ubuntu:20.04
  before_script:
    # Install global dependencies
    - apt-get update -y -qq -o=Dpkg::Use-Pty=0
    - apt-get install -y -qq -o=Dpkg::Use-Pty=0 curl rsync
    # Install ssh client
    - "which ssh-agent || ( apt-get install -y -qq -o=Dpkg::Use-Pty=0 openssh-client -y )"
    # - apk add openssh
    - eval $(ssh-agent -s)
    - echo "$SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh
    - echo "$KNOWN_HOSTS" >> ~/.ssh/known_hosts
    # Test that ssh client works
    - ssh strokach@conda-envs.proteinsolver.org "echo hello"
    # Install conda
    - curl -s -L https://repo.anaconda.com/miniconda/Miniconda3-py38_4.8.3-Linux-x86_64.sh > miniconda.sh
    - md5sum miniconda.sh | grep d63adf39f2c220950a063e0529d4ff74
    - sh miniconda.sh -b -p /opt/conda
    - source /opt/conda/etc/profile.d/conda.sh
    # - conda init
    - conda activate root
    - conda config --set channel_priority true # TODO: strict
    - conda config --set pip_interop_enabled false
    - conda install -n root -c conda-forge -y -q mamba conda-pack
  script:
    # Create conda environment
    - envsubst < .gitlab/conda-env/environment.yml > .gitlab/conda-env/environment.yml
    - conda env create -q -n ${ENVIRONMENT_NAME} -f .gitlab/conda-env/environment.yml
    - conda activate ${ENVIRONMENT_NAME}

    # Install pypi packages
    - pip install --no-use-pep517 -U -r .gitlab/conda-env/requirements.txt

    # Tests
    - python -c "import torch_sparse"
    - conda deactivate
    - conda list -n ${ENVIRONMENT_NAME}

    # Pack the environment
    - export ENVIRONMENT_FILE=${ENVIRONMENT_NAME}-${CI_COMMIT_REF_NAME}.tar.gz
    - conda pack -q -n ${ENVIRONMENT_NAME} -o ${ENVIRONMENT_FILE}
    - ls -lSh ${ENVIRONMENT_FILE}

    # Upload the environment to shared folder
    # - rsync -rv --info=progress2 -p --chmod=ug=rwX,o=rX "${ENVIRONMENT_FILE}" strokach@conda-envs.proteinsolver.org:/share/conda-envs/${ENVIRONMENT_NAME}/
  variables:
    ENVIRONMENT_NAME: "elaspic-v2"
  except:
    variables:
      - $UPDATE_IMAGES
  artifacts:
    paths:
      - ${ENVIRONMENT_FILE}

# === Lint ===

lint:
  stage: lint
  extends:
    - .configure
  script:
    - conda create -n lint -q "python=${PYTHON_VERSION}" isort toml flake8 mypy black
    - source activate lint
    - python -m isort -p ${CI_PROJECT_NAME} -c .
    - python -m flake8
    - python -m black --config pyproject.toml --check .
    # MyPy does not support namespace packages until this issue gets resolved:
    # https://github.com/python/mypy/issues/1645
    - python -m mypy -p ${CI_PROJECT_NAME} || true

# === Build ===

.build:
  stage: build
  extends:
    - .configure
  script:
    - conda install -yq conda conda-build conda-verify conda-forge-pinning
    - cd "${CI_PROJECT_DIR}/.gitlab/conda"
    - conda build .
      --variant-config-files /opt/conda/conda_build_config.yaml
      --no-test
      --python $PYTHON_VERSION
      --output-folder "$CI_PROJECT_DIR/conda-bld"
  artifacts:
    paths:
      - conda-bld

build-py37:
  extends: .build
  variables:
    <<: [*py37]

build-py38:
  extends: .build
  variables:
    <<: [*py38]

# === Test ===

.test:
  stage: test
  extends:
    - .configure
  script:
    # Create conda environment for testing
    - conda update -yq conda
    - conda create -n test -q -c file://${CI_PROJECT_DIR}/conda-bld --strict-channel-priority
      "python=${PYTHON_VERSION}" ${CI_PROJECT_NAME} pytest pytest-cov || true
    - source activate test
    # Run tests
    - PKG_INSTALL_DIR=$(python -c "import ev2; print(ev2.__path__[0])")
    - python -m pytest
      -c setup.cfg
      --cov="${PKG_INSTALL_DIR}"
      --cov-config=setup.cfg
      --color=yes
      "tests/"
    # Coverage
    - mkdir coverage
    - mv .coverage coverage/.coverage.all
  artifacts:
    paths:
      - coverage

test-py37:
  extends: .test
  dependencies:
    - build-py37

test-py38:
  extends: .test
  dependencies:
    - build-py38

# === Document ===

# NB: Has to be called "docs" for the pages script to work.
docs:
  stage: doc
  extends:
    - .configure
  script:
    # Create conda environment for testing
    - conda update -yq conda
    - conda create -n test -q -c file://${CI_PROJECT_DIR}/conda-bld --strict-channel-priority
      "python=${PYTHON_VERSION}" ${CI_PROJECT_NAME} nbconvert ipython ipykernel pandoc || true
    - source activate test
    - pip install -q sphinx sphinx_rtd_theme msmb_theme recommonmark sphinx-markdown-tables
      nbsphinx coverage
    # Build docs
    - sphinx-build ${CI_PROJECT_DIR}/docs public
    - ln -s . public/docs
    # Coverage
    - coverage combine coverage/
    - coverage report
    - coverage html
    - mv htmlcov public/
  coverage: /^TOTAL.* (\d+\%)/
  dependencies:
    - build-py38
    - test-py38
  artifacts:
    paths:
      - public
    when: always

# === Deploy ===

.deploy:
  stage: deploy
  extends:
    - .configure
  script:
    - anaconda -t $ANACONDA_TOKEN upload $CI_PROJECT_DIR/conda-bld/*/*.tar.bz2 -u ostrokach-forge --no-progress --force
  only:
    - tags
  allow_failure: true # TODO: Change when no longer testing.

deploy-py37:
  extends:
    - .deploy
  dependencies:
    - build-py37

deploy-py38:
  extends:
    - .deploy
  dependencies:
    - build-py38

deploy-pypi:
  stage: deploy
  extends:
    - .configure
  script:
    - python -m pip install -q twine wheel
    - python setup.py sdist bdist_wheel
    - twine upload dist/*
  only:
    - tags
  allow_failure: true # TODO: Change when no longer testing.

trigger-custom-pipelines:
  stage: deploy
  extends:
    - .skip-custom-pipelines
  image:
    name: ubuntu:18.04
  before_script:
    - apt-get -y -qq update
    - apt-get -y -qq install curl
  script:
    # Update pages
    - curl --request POST
      --form token="${CI_JOB_TOKEN}"
      --form ref=${CI_COMMIT_TAG}
      --form "variables[UPDATE_PAGES]=true"
      https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/trigger/pipeline
  only:
    - tags

# === Custom pipelines ===

pages:
  stage: custom
  before_script:
    - sudo yum update -y -q
    - sudo yum install -y -q unzip
    - pip install jinja2 python-gitlab
  script:
    # Set environment variables
    - export OUTPUT_DIR="./public"
    - mkdir -p ${OUTPUT_DIR}
    # Download all previous docs
    - python .gitlab/pages/download_docs.py
      --project-id ${CI_PROJECT_ID}
      --job-name docs
      --private-token ${CI_DOCS_TOKEN}
      --output-dir ${OUTPUT_DIR}
  artifacts:
    paths:
      - public
  only:
    variables:
      - $UPDATE_PAGES
