default:
  image: condaforge/linux-anvil-cos7-x86_64:latest

stages:
  - custom
  - lint
  - build
  - test
  - doc
  - deploy

# === Variables ===

variables:
  PACKAGE_VERSION: "0.1.2"
  PYTHON_VERSION: "3.8"
  CONDA_ENVIRONMENT: elaspic2
  GIT_LFS_SKIP_SMUDGE: 1

# === Configurations ===

.skip-custom-pipelines:
  except:
    variables:
      - $UPDATE_PAGES

.configure-conda:
  # Set conda envs and pkgs dirs
  script: &configure-conda
    - |
      cat <<EOF > ~/.condarc
      channel_priority: true
      channels:
        - pytorch
        - conda-forge
        - defaults
        - kimlab
        - ostrokach-forge
        - bioconda
        - salilab
        - https://${KIMLAB_CONDA_LOGIN}@conda.proteinsolver.org
        - https://${PYROSETTA_CONDA_LOGIN}@conda.graylab.jhu.edu
        - omnia
      EOF

# === Lint ===

lint:
  stage: lint
  extends:
    - .skip-custom-pipelines
  before_script:
    - *configure-conda
  script:
    - conda create -n lint -q "python=${PYTHON_VERSION}" isort toml flake8 mypy black
    - source activate lint
    - python -m isort -p elaspic2 -c .
    - python -m flake8
    - python -m black --config pyproject.toml --check .
    # MyPy does not support namespace packages until this issue gets resolved:
    # https://github.com/python/mypy/issues/1645
    - python -m mypy src || true

# === Build ===

build:
  stage: build
  extends:
    - .skip-custom-pipelines
  before_script:
    - *configure-conda
  script:
    - conda install -yq conda conda-build conda-verify conda-forge-pinning
    - cd "${CI_PROJECT_DIR}/.gitlab/conda"
    - >
      conda build .
      --variant-config-files /opt/conda/conda_build_config.yaml
      --variants "{python: [$PYTHON_VERSION], numpy: [1.16], python_impl: [cpython]}"
      --output-folder "$CI_PROJECT_DIR/conda-bld"
  artifacts:
    paths:
      - conda-bld

# === Test ===

test:
  stage: test
  image: ubuntu:20.04
  extends:
    - .skip-custom-pipelines
  before_script:
    # Install global dependencies
    - apt-get update -y -qq -o=Dpkg::Use-Pty=0
    - apt-get install -y -qq -o=Dpkg::Use-Pty=0 curl rsync gettext-base

    # Install ssh client
    - "which ssh-agent || ( apt-get install -y -qq -o=Dpkg::Use-Pty=0 openssh-client -y )"
    # - apk add openssh
    - eval $(ssh-agent -s)
    - echo "$SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh
    - echo "$KNOWN_HOSTS" >> ~/.ssh/known_hosts

    # Test that ssh client works
    - ssh strokach@conda-envs.proteinsolver.org "echo hello"

    # Install conda
    - curl -s -L https://repo.anaconda.com/miniconda/Miniconda3-py38_4.8.3-Linux-x86_64.sh > miniconda.sh
    - md5sum miniconda.sh | grep d63adf39f2c220950a063e0529d4ff74
    - sh miniconda.sh -b -p /opt/conda
    - source /opt/conda/etc/profile.d/conda.sh
    - conda activate root
    - conda install -n root -c conda-forge -y -q mamba conda-pack
    - *configure-conda
  script:
    # Create conda environment
    - envsubst < .gitlab/conda-env/environment.yml > .gitlab/conda-env/environment-subst.yml
    - cat .gitlab/conda-env/environment-subst.yml
    - conda env create -q -n ${CONDA_ENVIRONMENT} -f .gitlab/conda-env/environment-subst.yml

    # Install pypi packages
    - conda activate ${CONDA_ENVIRONMENT}
    - conda install -c file://${CI_PROJECT_DIR}/conda-bld ${CI_PROJECT_NAME}
    - pip install --no-use-pep517 -U -r .gitlab/conda-env/requirements.txt
    - conda list -n ${CONDA_ENVIRONMENT}

    # Tests
    - export SKIP_SLOW_TESTS=true
    - PKG_INSTALL_DIR=$(python -c "import elaspic2; print(elaspic2.__path__[0])")
    - python -c "import torch_sparse"
    - python -m pytest
      -c setup.cfg
      --cov="${PKG_INSTALL_DIR}"
      --cov-config=setup.cfg
      --color=yes
      --ignore="tests/plugins/modeller"
      --ignore="tests/plugins/rosetta_ddg"
      "tests/"
    - mkdir coverage
    - mv .coverage coverage/.coverage.base

    # Export the environment if building a release
    - |
      if [ "$CI_BUILD_REF_NAME" = "master" ]; then
        conda deactivate
        ENVIRONMENT_FILE=${CONDA_ENVIRONMENT}-${CI_COMMIT_REF_NAME}.tar.gz
        conda pack -q -n ${CONDA_ENVIRONMENT} -o ${ENVIRONMENT_FILE}
        ls -lSh ${ENVIRONMENT_FILE}
        rsync -rv --info=progress2 -p --chmod=ug=rwX,o=rX "${ENVIRONMENT_FILE}" strokach@conda-envs.proteinsolver.org:/share/conda-envs/${CONDA_ENVIRONMENT}/
        conda activate ${CONDA_ENVIRONMENT}
      fi

    # Install optional dependencies
    - conda install "modeller=9.25" "pyrosetta=2020.37+release.3ba1aaa" "rosetta-ddg=2020.37"

    # Test optional plugins
    - python -m pytest
      -c setup.cfg
      --cov="${PKG_INSTALL_DIR}"
      --cov-config=setup.cfg
      --color=yes
      --ignore="tests/plugins/modeller"
      --ignore="tests/plugins/rosetta_ddg"
      "tests/"
    - mkdir coverage
    - mv .coverage coverage/.coverage.extra
  dependencies:
    - build
  artifacts:
    paths:
      - coverage

# === Document ===

# NB: Has to be called "docs" for the pages script to work.
docs:
  stage: doc
  extends:
    - .skip-custom-pipelines
  before_script:
    - *configure-conda
  script:
    # Create conda environment for testing
    - conda update -yq conda
    - conda create -n test -q -c file://${CI_PROJECT_DIR}/conda-bld --strict-channel-priority
      "python=${PYTHON_VERSION}" ${CI_PROJECT_NAME} nbconvert ipython ipykernel pandoc || true
    - source activate test
    - pip install -q sphinx sphinx_rtd_theme msmb_theme recommonmark sphinx-markdown-tables
      nbsphinx coverage
    # Build docs
    - sphinx-build ${CI_PROJECT_DIR}/docs public
    - ln -s . public/docs
    # Coverage
    - coverage combine coverage/
    - coverage report
    - coverage html
    - mv htmlcov public/
  coverage: /^TOTAL.* (\d+\%)/
  dependencies:
    - build
    - test
  artifacts:
    paths:
      - public
    when: always

# === Deploy ===

deploy:
  stage: deploy
  extends:
    - .skip-custom-pipelines
  before_script:
    - *configure-conda
  script:
    - anaconda -t $ANACONDA_TOKEN upload $CI_PROJECT_DIR/conda-bld/*/*.tar.bz2 -u ostrokach-forge --no-progress --force
  only:
    - tags
  allow_failure: true # TODO: Change when no longer testing.
  dependencies:
    - build

deploy-pypi:
  stage: deploy
  extends:
    - .skip-custom-pipelines
  before_script:
    - *configure-conda
  script:
    - python -m pip install -q twine wheel
    - python setup.py sdist bdist_wheel
    - twine upload dist/*
  only:
    - tags
  allow_failure: true # TODO: Change when no longer testing.

trigger-custom-pipelines:
  stage: deploy
  extends:
    - .skip-custom-pipelines
  image:
    name: ubuntu:18.04
  before_script:
    - apt-get -y -qq update
    - apt-get -y -qq install curl
  script:
    # Update pages
    - curl --request POST
      --form token="${CI_JOB_TOKEN}"
      --form ref=${CI_COMMIT_TAG}
      --form "variables[UPDATE_PAGES]=true"
      https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/trigger/pipeline
  only:
    - tags

# === Custom pipelines ===

pages:
  stage: custom
  before_script:
    - sudo yum update -y -q
    - sudo yum install -y -q unzip
    - pip install jinja2 python-gitlab
  script:
    # Set environment variables
    - export OUTPUT_DIR="./public"
    - mkdir -p ${OUTPUT_DIR}
    # Download all previous docs
    - python .gitlab/pages/download_docs.py
      --project-id ${CI_PROJECT_ID}
      --job-name docs
      --private-token ${CI_DOCS_TOKEN}
      --output-dir ${OUTPUT_DIR}
  artifacts:
    paths:
      - public
  only:
    variables:
      - $UPDATE_PAGES
